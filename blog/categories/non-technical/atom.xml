<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Non-Technical | Quantified Savagery]]></title>
  <link href="http://blog.savageevan.com/blog/categories/non-technical/atom.xml" rel="self"/>
  <link href="http://blog.savageevan.com/"/>
  <updated>2013-03-04T17:08:58-08:00</updated>
  <id>http://blog.savageevan.com/</id>
  <author>
    <name><![CDATA[Evan Savage]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Another Quadtree Map Rendering]]></title>
    <link href="http://blog.savageevan.com/blog/2013/03/04/another-quadtree-map-rendering/"/>
    <updated>2013-03-04T16:48:00-08:00</updated>
    <id>http://blog.savageevan.com/blog/2013/03/04/another-quadtree-map-rendering</id>
    <content type="html"><![CDATA[<p>This will be a quick post: I’ve got another population-based map rendering to
share, based on the work described in <a href="http://blog.savageevan.com/blog/2013/02/21/quadtree-cartography/">this post</a>.</p>

<!-- more -->

<h2 id="the-rendering">The Rendering</h2>

<p>This rendering uses tiles at Google Maps zoom level 14:</p>

<p><img src="https://lh5.googleusercontent.com/-74zVhVDHIdc/UTVAtI4bhcI/AAAAAAAAAWY/sWT9JplWl7k/s800/tiles14.2048.jpg"></p>

<p>I decided to experiment with solid shading rather than wireframe for the tiles.
This cuts down on the <a href="http://en.wikipedia.org/wiki/Moir%C3%A9_pattern">Moiré effect</a>
in densely populated areas.</p>

<p>The original is a <em>whopping 1 gigapixels</em>, so I had to resize it using
<a href="http://www.imagemagick.org/script/index.php">ImageMagick</a> before uploading it to Picasa:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ convert tiles14.jpg -sample 2048x2048 tiles14.2048.jpg</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>A few more random tidbits of information:</p>

<ul>
  <li>Computing the tile subdivision <em>took one CPU-hour</em> on my laptop, a fairly
new MacBook Air.</li>
  <li>At zoom level 14, tiles near the equator are <em>roughly 1.5 miles to a side.</em>
(Tiles further north or south are shorter in the north-south direction
due to distortion in the Mercator projection.)</li>
  <li><em>The Nile is clearly visible</em> between the Nile Delta and Aswan.</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Quadtree Cartography]]></title>
    <link href="http://blog.savageevan.com/blog/2013/02/21/quadtree-cartography/"/>
    <updated>2013-02-21T10:05:00-08:00</updated>
    <id>http://blog.savageevan.com/blog/2013/02/21/quadtree-cartography</id>
    <content type="html"><![CDATA[<p>In this post, I show off some images from a project I’m working on (which will
remain nameless for now!) These images visualize subdivisions of the Earth
into Google Maps tile-sized regions with roughly equal population. I’ll also
provide a brief and non-technical rundown of the process by which I generated
these images.</p>

<!-- more -->

<h2 id="the-images">The Images</h2>

<p>First, a representative image from my renderings:</p>

<p><img src="https://lh5.googleusercontent.com/-EmN0ma8uhtg/USZnFkGsrfI/AAAAAAAAAV8/hDpa5sx1-IE/s640/tiles11.ag.jpg"></p>

<p>I love working on problems with a visual aspect - you get direct sensory
feedback on your progress!</p>

<p>Here, we can clearly see the continents delineated
by dense coastal population clusters. India and China are especially detailed,
and Europe has fairly uniform density throughout. Contrast this with North
America: northern Canada is sparsely populated, as are the deserts and
mountains of the Central United States.</p>

<p>Next, some renderings at different subdivision levels (Google Maps zoom
levels 8-11):</p>

<p><img src="https://lh4.googleusercontent.com/-SqLGYcz6yl0/USZnBXDoUNI/AAAAAAAAAUs/C7vdLkL522Y/s288/tiles8.ag60.jpg">
<img src="https://lh5.googleusercontent.com/-m2wk-ov9Mw4/USZnBmDUucI/AAAAAAAAAU0/vrU48gzJei4/s288/tiles9.ag60.jpg">
<img src="https://lh6.googleusercontent.com/-GuXnAIjWUf0/USZnCbAac_I/AAAAAAAAAU8/urh1UXBD3-U/s288/tiles10.ag60.jpg">
<img src="https://lh6.googleusercontent.com/-Y53pPe7T0II/USZnCn5ZL3I/AAAAAAAAAVI/Owjf_pnQBic/s288/tiles11.ag60.jpg"></p>

<p>As the subdivision level increases, the continents progress from blocky pixel
art to more recognizable shapes.</p>

<p>Finally, some renderings with different resolutions of the underlying population
data (degree, half-degree, quarter-degree, and 2.5 arc minutes):</p>

<p><img src="https://lh6.googleusercontent.com/-GuXnAIjWUf0/USZnCbAac_I/AAAAAAAAAU8/urh1UXBD3-U/s288/tiles10.ag60.jpg">
<img src="https://lh6.googleusercontent.com/-RRw5Gx4OiaA/USZnEQhqNhI/AAAAAAAAAVg/i6B3yx8BF_M/s288/tiles10.ag30.jpg">
<img src="https://lh5.googleusercontent.com/-NkGpf7zzHsY/USZnFI4qQ7I/AAAAAAAAAV4/Kl1UB4U-4pU/s288/tiles10.ag15.jpg">
<img src="https://lh6.googleusercontent.com/-n6Ufe_6mJzM/USZnF60IfvI/AAAAAAAAAWE/PEmAgvWvzNU/s288/tiles10.ag.jpg"></p>

<p>Here the effect is more subtle: detail is added in densely populated areas,
but larger tiles (corresponding to more remote regions) are mostly unaffected.</p>

<p>To see all the images as small multiples, <a href="https://picasaweb.google.com/100933554722754572774/20130221QuadtreeCartography#">view the album on Picasa</a>.</p>

<h2 id="the-process">The Process</h2>

<p>There are four major steps: getting the data, combining it with Google Maps
tile data, building the subdivision, and rendering it.</p>

<h3 id="getting-the-data">Getting the Data</h3>

<p>The <a href="http://sedac.ciesin.columbia.edu/citations">NASA Socio-Economic Data and Applications Center</a>,
or SEDAC, compiles global population grids. These grids contain the estimated
number of people living in each 2.5-arc-minute square of the Earth’s surface.
2.5 arc-minutes is 1/24 of a degree, or about 4.5 km of equatorial circumference:
definitely high-resolution enough for building some awesome maps!</p>

<p>The population count grids are available <a href="http://sedac.ciesin.columbia.edu/data/set/gpw-v3-population-count/data-download">here</a>.
You have to register on the site and cite usage of their data, but otherwise it
appears to be freely available.</p>

<h3 id="combining-with-google-maps">Combining with Google Maps</h3>

<p>Google Maps uses a <a href="http://en.wikipedia.org/wiki/Mercator_projection">Mercator projection</a>.
This projection is <a href="https://developers.google.com/maps/documentation/javascript/maptypes#WorldCoordinates">truncated</a>
at roughly 85 degrees latitude to create a square map, which is then projected
onto a 256 x 256 world coordinate system. Finally, world coordinates are
mapped to <a href="https://developers.google.com/maps/documentation/javascript/maptypes#PixelCoordinates">pixel coordinates</a>
at different zoom levels, which determine which <a href="https://developers.google.com/maps/documentation/javascript/maptypes#TileCoordinates">tile</a>
your location falls in.</p>

<p>To match up the gridded population data with Google Maps tiles, then, we need
to do the following:</p>

<ul>
  <li>for each grid cell, <em>determine its latitude and longitude boundaries</em>;</li>
  <li>use those boundaries to <em>figure out which map tiles the cell overlaps</em>;</li>
  <li><em>divide the cell’s population among those map tiles</em>.</li>
</ul>

<p>To divide the cell’s population fairly, I determine how much of the cell
overlaps each tile.</p>

<p>I found <a href="https://google-developers.appspot.com/maps/documentation/javascript/examples/map-coordinates">this helpful example</a>
of working with locations, world coordinates, pixel coordinates, and tiles.
The source code of that example contains an implementation of Google’s
Mercator projection, which I built into a larger <a href="http://nodejs.org/">node.js</a>
utility for computing the equal-population subdivision.</p>

<p>(Yes, node.js is fine for CPU-intensive tasks, just not in the same process
as your webserver.)</p>

<h3 id="building-an-equal-population-subdivision">Building an Equal-Population Subdivision</h3>

<p>To get map tiles of equal population, <em>I combine tiles into larger tiles
until the population exceeds a threshold.</em> This creates large tiles in
sparsely populated areas while leaving smaller tiles in densely populated
areas.</p>

<p>(I mentioned <a href="http://blog.notdot.net/2009/11/Damn-Cool-Algorithms-Spatial-indexing-with-Quadtrees-and-Hilbert-Curves">quadtrees</a>
in the title of this post - this data structure is ideally suited for the
problem.)</p>

<h3 id="rendering-the-subdivision">Rendering the Subdivision</h3>

<p>This is the easy part! I used <a href="https://pypi.python.org/pypi/Pillow/">Pillow</a>, a
nicely-packaged version of the excellent <a href="http://www.pythonware.com/products/pil/">Python Imaging Library</a>,
to render the subdivisions out as JPEG images.</p>

<p>(I suppose I could have rendered SVG images in node.js using some <a href="https://github.com/tmpvar/jsdom">jsdom</a>
and <a href="http://d3js.org/">d3</a> hackery, but I was already familiar with using
Python Imaging Library for image synthesis.)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What I'll Look Like In 50 Years]]></title>
    <link href="http://blog.savageevan.com/blog/2013/01/31/what-ill-look-like-in-50-years/"/>
    <updated>2013-01-31T12:43:00-08:00</updated>
    <id>http://blog.savageevan.com/blog/2013/01/31/what-ill-look-like-in-50-years</id>
    <content type="html"><![CDATA[<p>I spent a few weeks in the not-so-frozen Canadian northlands over the winter
holidays. While there, I had the chance to visit an old childhood favorite:
the <a href="http://ontariosciencecentre.ca/">Ontario Science Centre</a>, six floors of science-based awesomeness.
One of their current exhibits, the <a href="http://ontariosciencecentre.ca/aging/">Amazing Aging Machine</a>, uses a
computer vision software package called <a href="http://aprilage.com/">APRIL</a> to predict how your
face will change over the next 50 years.</p>

<p>In this post, I explore my results from that exhibit alongside a customized
aging I performed using the <a href="http://www.aprilage.com/AprilAPI_V2.pdf">APRIL API</a>.</p>

<!-- more -->

<h2 id="present-me">Present Me</h2>

<p>It’s not the most flattering photo, but here I am at 26:</p>

<p><img src="https://lh4.googleusercontent.com/-8qaAivSLFrI/UQrbKiU3JZI/AAAAAAAAARY/9e7IvKZUB00/s288/aging1.jpg"></p>

<h2 id="future-me">Future Me</h2>

<h3 id="take-one-amazing-aging-machine">Take One: Amazing Aging Machine</h3>

<p>First, my face balloons out massively:</p>

<p><img src="https://lh4.googleusercontent.com/-LCFkNNtDiJg/UQrbKwGOIQI/AAAAAAAAARg/SS9o98axBtU/s288/aging2.jpg"></p>

<p>Next, my cheek bones set downwards:</p>

<p><img src="https://lh5.googleusercontent.com/-VZhuI1uOVQk/UQrbLTKdBXI/AAAAAAAAARo/LHKV6cGEBGA/s288/aging3.jpg">
<img src="https://lh6.googleusercontent.com/-aNcc-FC_4yk/UQrbL53IPpI/AAAAAAAAARs/DRf3ySCxPs4/s288/aging4.jpg"></p>

<p>Finally, my face leans up and wrinkles a tiny bit:</p>

<p><img src="https://lh6.googleusercontent.com/-F8xBzpDWsM4/UQrbMUOukwI/AAAAAAAAAR0/cRqPDd_wYPM/s288/aging5.jpg"></p>

<h3 id="take-two-april-api">Take Two: APRIL API</h3>

<p>For this run, I had access to the raw aging metadata, so I could see
exactly how old APRIL thought I was at each point in the aging sequence.</p>

<p>From 26 to 28, there’s not much change:</p>

<p><img src="https://lh6.googleusercontent.com/-u36fDGLeI0Y/UQrbNrKtZyI/AAAAAAAAASE/NQSn0Y5uCng/s288/age28.jpg"></p>

<p>Then, by age 35, my face elongates slightly:</p>

<p><img src="https://lh4.googleusercontent.com/-cRxKskiAyos/UQrbOiA_OjI/AAAAAAAAASM/GBFlRfZtXnc/s288/age35.jpg"></p>

<p>I while away the next couple of decades in relative facial stasis. The
most pronounced change is in my skin, which pales gradually with age:</p>

<p><img src="https://lh6.googleusercontent.com/-gYCoSmKbBDw/UQrbO46gohI/AAAAAAAAASY/X8RoWKpGT_8/s288/age47.jpg">
<img src="https://lh6.googleusercontent.com/-dWkaa-neumY/UQrbPgkBVtI/AAAAAAAAASg/ebWh4i14qYk/s288/age55.jpg"></p>

<p>Finally, age catches up with me, and I wrinkle into a haunted
septuagenarian:</p>

<p><img src="https://lh5.googleusercontent.com/-JNBO6QMu-Xg/UQrbP9uzUUI/AAAAAAAAASo/Dj43_1l46Zo/s288/age61.jpg">
<img src="https://lh4.googleusercontent.com/-w7zx8Ql3PnM/UQrbQO2pqVI/AAAAAAAAASw/9HJrW1EUz2c/s288/age67.jpg">
<img src="https://lh5.googleusercontent.com/-RNgo0CglAjs/UQrbQtlY69I/AAAAAAAAAS0/OXD8Yqf63og/s288/age72.jpg"></p>

<p>A few changes, each very minor, contribute to my forlorn expression over
these last three photos.</p>

<ul>
  <li>The <em>eyes get slightly rounder</em>, as though they’re welling up.</li>
  <li><em>Wrinkling above the eyes</em> gives the impression of a furrowed brow.</li>
  <li>The face <em>elongates yet again</em>, creating a drawn expression.</li>
  <li>As part of the elongation of the face, the <em>mouth corners sag downwards</em>
into the merest hint of a frown.</li>
</ul>

<p>Note the lack of deep forehead and upper nose creases which normally
accompany the furrowed brow expression. The mere suggestion of it on the eyes
is enough to trigger our expression recognition! It’s amazing how sensitive
we are to minute variations in facial muscle position.</p>

<h3 id="summary">Summary</h3>

<p>These images provide two divergent visions for my distant future:</p>

<p><img src="https://lh6.googleusercontent.com/-F8xBzpDWsM4/UQrbMUOukwI/AAAAAAAAAR0/cRqPDd_wYPM/s288/aging5.jpg">
<img src="https://lh5.googleusercontent.com/-RNgo0CglAjs/UQrbQtlY69I/AAAAAAAAAS0/OXD8Yqf63og/s288/age72.jpg"></p>

<p>For comparison, here’s my father in his late 50s, looking quite a bit happier:</p>

<p><img src="http://farm4.staticflickr.com/3177/2828216200_5846e31c4a_z.jpg"></p>

<h2 id="why-were-those-so-different">Why Were Those So Different?</h2>

<p><blockquote><p>…the machine uses state-of-the-art aging software developed in partnership with Aprilage Development Inc. of Toronto to add decades to the faces of 8-12 year olds.</p><footer><strong>The Amazing Aging Machine</strong> <cite><a href='http://ontariosciencecentre.ca/aging/'>ontariosciencecentre.ca/aging/&hellip;</a></cite></footer></blockquote></p>

<p>The Amazing Aging Machine is calibrated for ages 8-12, likely to match 
the Ontario Science Centre’s target demographic. (Sadly, I couldn’t find
detailed visitor demographic data!) In my case, this creates an awkward
puffy look: it’s applying changes in facial structure through adolescence,
when much of our bone growth occurs.</p>

<p>By contrast, the APRIL API asks for your current age, allowing it to more
correctly calibrate its models. As a result, the second set of faces exhibits
relatively little change in shape.</p>

<h2 id="what-do-i-get-out-of-this">What Do I Get Out Of This?</h2>

<p>Although my face is unlikely to match either of these faces at 72, this
experiment provides some insight into how our faces change with age. After
all, the APRIL face aging models are based on real face data. They represent
a sort of statistical average of the aging process.</p>

<p>Also, I get the vaguely warm feeling that comes with having contributed to our
<a href="http://vimeo.com/29052688">collective intelligence</a>. I provided APRIL
with a real age-labelled face, which will likely be used to help train future
models.</p>

<h2 id="appendix-how-to-use-the-april-api">Appendix: How To Use The APRIL API</h2>

<p>For the more technically-minded, I’ve provided a quick walkthrough of the
API aging pipeline. For all the gritty details, consult the <a href="http://www.aprilage.com/AprilAPI_V2.pdf">API docs</a>.</p>

<p>Before starting, I highly recommend installing a tool like <a href="https://github.com/jmhodges/jsonpp">jsonpp</a>;
it makes it much easier to read API results.</p>

<p>The first step is manual: you need to register at <a href="http://www.ageme.com/">ageme.com</a>, then
click the confirmation link in your email.</p>

<p><img src="https://lh5.googleusercontent.com/-wuu_sRDb7qQ/UQrtRmoofNI/AAAAAAAAATE/l7CAexc1_ZY/s400/ageme_register.jpg"></p>

<p>The next step is uploading an image, but let’s check first that the API
works by retrieving our user info:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl http://www.ageme.com/AprilAPI/users/savage.evan@gmail.com/userInfo
</span><span class='line'>{“result_code”:0,”message”:”Unauthorized”}</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Oops! We haven’t authenticated ourselves. The Authorization header uses a
brain-dead and highly insecure <code>base64</code> encoding:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ python -c “import base64; print base64.encodestring(‘username:password’)”
</span><span class='line'>dXNlcm5hbWU6cGFzc3dvcmQ=</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>(Obviously this isn’t my real username/password. Substitute yours above and
use the resulting <code>base64</code>-encoded string in the <code>Authorization</code> headers
below. I’ll use this bogus value to illustrate the flow.)</p>

<p>With the correct header, we can try fetching the user info again:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -H “Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=” http://www.ageme.com/AprilAPI/users/savage.evan@gmail.com/userInfo | jsonpp 
</span><span class='line'>{
</span><span class='line'>  “uri”: “http://www.ageme.com/AprilAPI/users/savage.evan@gmail.com”,
</span><span class='line'>  “email”: “savage.evan@gmail.com”,
</span><span class='line'>  “tokens”: 0,
</span><span class='line'>  “numOfAgings”: 1,
</span><span class='line'>  “role”: “user”
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Great! Now we can POST an image to the uploading endpoint with <code>curl</code>:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -F ‘filename=aging1.jpg’ -F ‘image=@/Users/candu/Desktop/aging1.jpg’ -H “Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=” http://www.ageme.com/AprilAPI/images</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Another manual step: before proceeding, you’ll need to purchase a token on
the <a href="http://www.ageme.com/">ageme.com</a> site. At time of writing, this cost $3.99; I looked for
active promotion codes, but couldn’t find any.</p>

<p><img src="https://lh6.googleusercontent.com/-co9vyFu4uJQ/UQrtSM1T8mI/AAAAAAAAATM/8ozrK3aiGjk/s400/ageme_buytokens.jpg"></p>

<p>With your aging token purchased, you can now create an aging document. This
lets APRIL know your age and ethnicity, which helps it to select the
appropriate models for your particular aging sequence. It also identifies the
starting image of that sequence via the <code>imageId</code> returned during image upload.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -H ‘Content-Type: application/json’ -d ‘{“document”: {“gender”: “male”, “age”: 26, “name”: “Evan”, “ethnicity”: “Caucasian”}, “imageId”: 2371944}}’ -H “Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=” http://www.ageme.com/AprilAPI/documents</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>We’re ready to run the aging process. There’s a single method <code>detectMatchAge</code>
for performing all three steps, but I’ll break it down into the component
steps here:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X POST -H “Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=” http://www.ageme.com/AprilAPI/users/savage.evan@gmail.com/documents/2371973/pointDetection
</span><span class='line'>$ while true; do curl -H “Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=” http://www.ageme.com/AprilAPI/users/savage.evan@gmail.com/documents/2371973/status; done
</span><span class='line'>$ curl -X POST -H “Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=” http://www.ageme.com/AprilAPI/users/savage.evan@gmail.com/documents/2371973/match
</span><span class='line'>$ while true; do curl -H “Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=” http://www.ageme.com/AprilAPI/users/savage.evan@gmail.com/documents/2371973/status; done
</span><span class='line'>$ curl -H ‘Content-Type: application/json’ -d ‘{“sequenceType”: “Max72”, “sequences”: [{“smoking”: 0, “sunExposure”: 0, “multiplier”: 1}]}’ -H “Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=” http://www.ageme.com/AprilAPI/users/savage.evan@gmail.com/documents/2371973/aging
</span><span class='line'>$ while true; do curl -H “Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=” http://www.ageme.com/AprilAPI/users/savage.evan@gmail.com/documents/2371973/status; done</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Note the <code>while</code> loops, which wait for each step to complete. Once all steps
are completed, we retrieve the aging results:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -H “Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=” http://www.ageme.com/AprilAPI/users/savage.evan@gmail.com/documents/2371973/results &gt; aging_results.json
</span><span class='line'>$ cat aging_results.json | jsonpp | head -15
</span><span class='line'>[
</span><span class='line'>  {
</span><span class='line'>    “uri”: “http://www.ageme.com/AprilAPI/users/savage.evan@gmail.com/documents/2371973/results/76647”,
</span><span class='line'>    “status”: “done”,
</span><span class='line'>    “sequenceType”: “Max72”,
</span><span class='line'>    “sequences”: [
</span><span class='line'>      {
</span><span class='line'>        “smoking”: 0.0,
</span><span class='line'>        “sunExposure”: 0.0,
</span><span class='line'>        “multiplier”: 1.0,
</span><span class='line'>        “images”: [
</span><span class='line'>          {
</span><span class='line'>            “age”: 26,
</span><span class='line'>            “uri”: “http://www.ageme.com/AprilAPI/images/IhLAo8Sp”
</span><span class='line'>          },</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Finally, I wrote a bit of <a href="https://github.com/candu/quantified-savagery-files/blob/master/Aging/fetch_aging.py">Python glue</a> to fetch the URLs and name
them by age:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='py'><span class='line'><span class="kn">import</span> <span class="nn">json</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">sys</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">urllib2</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span><span class='line'><span class="n">images</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="err">‘</span><span class="n">sequences</span><span class="err">’</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="err">‘</span><span class="n">images</span><span class="err">’</span><span class="p">]</span>
</span><span class='line'><span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
</span><span class='line'>  <span class="n">url</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="err">‘</span><span class="n">uri</span><span class="err">’</span><span class="p">])</span>
</span><span class='line'>  <span class="n">path</span> <span class="o">=</span> <span class="err">‘</span><span class="n">age</span><span class="p">{</span><span class="mi">0</span><span class="p">}</span><span class="o">.</span><span class="n">jpg</span><span class="err">’</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="err">‘</span><span class="n">age</span><span class="err">’</span><span class="p">])</span>
</span><span class='line'>  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="err">‘</span><span class="n">w</span><span class="err">’</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span class='line'>    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">url</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>With this, we can fetch the images:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ python fetch_aging.py &lt; aging_results.json</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>And that’s it! Most of the process uses <code>curl</code>, with minimal leaning
on Python for its <code>base64</code> module.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[datafist: Exploration And Analysis]]></title>
    <link href="http://blog.savageevan.com/blog/2012/12/21/datafist-exploration-and-analysis/"/>
    <updated>2012-12-21T07:00:00-08:00</updated>
    <id>http://blog.savageevan.com/blog/2012/12/21/datafist-exploration-and-analysis</id>
    <content type="html"><![CDATA[<p>In this post I introduce datafist, an in-browser tool for visually exploring
your data. </p>

<!-- more -->

<h2 id="first-a-quote">First, A Quote</h2>

<p><blockquote><p>Are we analyzing data? Then we should be manipulating the data themselves; or if we are designing an analysis of data, we should be manipulating the analytic structures themselves.</p><footer><strong>Direct Manipulation Interfaces</strong> <cite><a href='http://cleo.ics.uci.edu/teaching/Winter10/231/readings/1-HutchinsHollanNorman-DirectManipulation-HCI.pdf'>cleo.ics.uci.edu/teaching/231/&hellip;</a></cite></footer></blockquote></p>

<h2 id="the-sixfold-path-of-self-tracking">The Sixfold Path Of Self-Tracking</h2>

<p>Self-tracking is a complex process. It can be broken down into stages:</p>

<ul>
  <li><em>Intent:</em> our initial goals or motivations in deciding to self-track.</li>
  <li><em>Tools:</em> the devices or methods we use for tracking.</li>
  <li><em>Measurement:</em> collecting our data using those tools.</li>
  <li><em>Analysis:</em> extracting insights from our data.</li>
  <li><em>Interpretation:</em> creating personal meaning from those insights.</li>
  <li><em>Action:</em> responding to that personal meaning.</li>
</ul>

<p>Thanks to smartphones and cheap sensors, many of us already have the tools
necessary for measurement. The psychology of intent and action is rapidly
being explored through <a href="http://www.meetup.com/habitdesign/">Habit Design</a> and <a href="http://captology.stanford.edu/">Captology</a>, with
startups like <a href="http://lift.do/">Lift</a> and <a href="https://www.beeminder.com/">Beeminder</a> harnessing the findings
to great effect.</p>

<p><em>What are the technologies of analysis and interpretation?</em></p>

<h3 id="visualization">Visualization</h3>

<p>Visualizations, even interactive ones, are usually designed to <em>answer
specific questions</em> such as <a href="http://www.nytimes.com/interactive/2012/11/07/us/politics/obamas-diverse-base-of-support.html">how did Obama win re-election?</a>
Within the context of those questions, they help us understand our data
intuitively. Outside that context, however, they are often useless.</p>

<h3 id="statisticalmathematical-software">Statistical/Mathematical Software</h3>

<p>Environments like <a href="http://www.r-project.org/">R</a> and <a href="http://www.wolfram.com/mathematica/">Mathematica</a> allow you to <em>explore
your data in meticulous detail.</em> In the hands of people like
<a href="http://blog.stephenwolfram.com/2012/03/the-personal-analytics-of-my-life/">Stephen Wolfram</a>, they are the holy grail of data analysis. For the
less technically inclined, they remain hopelessly unintuitive.</p>

<h2 id="a-middle-road">A Middle Road</h2>

<p>What we need is <em>something between the two</em>, a hybrid that exposes the
exploratory power of the latter through the intuitive interface of the former.
Such a tool would give us the opportunity to <em>explore our data as we see fit.</em>
We could ask our data questions, iterating quickly on those questions until
we reach useful insights.</p>

<p>Until we can all converse with our data with the fluency of <a href="http://www.ted.com/talks/hans_rosling_the_good_news_of_the_decade.html">Hans Rosling</a>,
there’s still room for improvement!</p>

<h2 id="datafist">datafist</h2>

<p>datafist tries to bridge this gap by providing <em>visual and gestural actions</em>
for data manipulation. This is probably easier to demonstrate than describe,
so here’s a screencast that shows an early development version of datafist
in action:</p>

<div>
  <iframe width="560" height="315" src="http://www.youtube.com/embed/ypitHPXKa8M" frameborder="0" allowfullscreen=""></iframe>
</div>

<p>As you use datafist, <em>you’re constantly modifying the analysis itself.</em>
This modification takes place through <em>visual and gestural actions:</em> you
move channels to the viewer, drag out ranges of time to zoom in on, and draw
regions around interesting clusters. As you do this, the view is
<em>updated in real-time</em>, allowing you to see the effects of your actions.</p>

<h3 id="try-datafist-out">Try datafist Out!</h3>

<p>I’m hosting a version of datafist <a href="http://datafist.savageevan.com">here at savageevan.com</a>.
Note that this is still a very early development version!</p>

<h3 id="contribute-to-datafist">Contribute to datafist!</h3>

<p>If you’re interested in making datafist better, <a href="https://github.com/candu/datafist">fork me on github!</a>
Bug reports should be submitted <a href="https://github.com/candu/datafist/issues">via the issue tracker</a>.
In particular, if you have a CSV file that won’t import properly, please attach
it for testing purposes!</p>

<h2 id="inspiration">Inspiration</h2>

<ul>
  <li><a href="http://www.audiomulch.com/">AudioMulch</a> is an awesome graphical audio synthesis tool.</li>
  <li><a href="http://puredata.info/">PureData</a> and <a href="http://cycling74.com/products/max/">Max/MSP</a> are visual signal processing languages.</li>
  <li><a href="http://cleo.ics.uci.edu/teaching/Winter10/231/readings/1-HutchinsHollanNorman-DirectManipulation-HCI.pdf">Direct Manipulation Interfaces</a> is a classic paper on the design of
natural-seeming interfaces. You’ll recognize some of the interface concepts
from the analysis package design mocks at the beginning.</li>
  <li><a href="http://www.startuplessonslearned.com/2011/11/startup-is-vision.html">FAKEGRIMLOCK</a> is a fountain of poorly-Englished wisdom on
entrepreneurship.</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sober Thoughts On Willpower And Decision Making]]></title>
    <link href="http://blog.savageevan.com/blog/2012/11/14/sober-thoughts-on-willpower-and-decision-making/"/>
    <updated>2012-11-14T07:00:00-08:00</updated>
    <id>http://blog.savageevan.com/blog/2012/11/14/sober-thoughts-on-willpower-and-decision-making</id>
    <content type="html"><![CDATA[<p>In this post, I discuss my ongoing experiment with eliminating alcohol from my
diet. I use this experience to address a question: why do we find some forms of
habit change easier than others?</p>

<!-- more -->

<h2 id="background">Background</h2>

<p>As of today, <em>I’ve been completely sober for over a month.</em> I took my last drink
at <a href="http://goo.gl/maps/nSxLn">Seven’s Ale House</a> on October 13 with these
fine folks:</p>

<p><img src="https://lh6.googleusercontent.com/-chtv-noAeXM/UKQNQdVUz1I/AAAAAAAAANQ/8zTq_kKfbCU/s640/sevens-pub.jpg"></p>

<p>Why did I decide to do this? One of the takeaways from my
<a href="/blog/2012/10/14/self-tracking-for-panic-another-dataset/">self-tracking for panic</a>
was that <em>I drink heavily and frequently:</em> about three drinks per day, six days
per week. The USDA recommendations are somewhat stricter:</p>

<p><blockquote><p>…“low-risk” drinking [is defined] as no more than 14 drinks a week for men and 7 drinks a week for women with no more than 4 drinks on any given day for men and 3 drinks a day for women.</p><footer><strong>Dietary Guidelines for Americans</strong> <cite><a href='http://www.cnpp.usda.gov/Publications/DietaryGuidelines/2010/DGAC/Report/D-7-Alcohol.pdf'>www.cnpp.usda.gov/Publications/&hellip;</a></cite></footer></blockquote></p>

<p><a href="http://www.alcoholscreening.org/Home.aspx">This online questionnaire</a> put my drinking level in context:</p>

<p><img src="https://lh5.googleusercontent.com/-ieizYGUAwJo/UKQNQsFeBOI/AAAAAAAAANY/jZ1_09uBSqk/s800/percentile-drinking.jpg"></p>

<p><em>How much does the average American drink?</em> Using the data from
<a href="http://en.wikipedia.org/wiki/List_of_countries_by_alcohol_consumption">this Wikipedia article</a>
and some simple calculations:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='py'><span class='line'><span class="c"># 1 drink = 1 beer bottle (355mL, 5% abv)</span>
</span><span class='line'><span class="n">ALC_PER_BEER</span> <span class="o">=</span> <span class="mf">0.355</span> <span class="o">*</span> <span class="mf">0.05</span>
</span><span class='line'><span class="c"># American consumption = 9.44 L/year</span>
</span><span class='line'><span class="n">DRINKS_PER_YEAR</span> <span class="o">=</span> <span class="mf">9.44</span> <span class="o">/</span> <span class="n">ALC_PER_BEER</span>
</span><span class='line'><span class="c"># 1 year = 365 days</span>
</span><span class='line'><span class="n">DRINKS_PER_DAY</span> <span class="o">=</span> <span class="n">DRINKS_PER_YEAR</span> <span class="o">/</span> <span class="mi">365</span>
</span><span class='line'><span class="k">print</span> <span class="n">DRINKS_PER_DAY</span>
</span><span class='line'><span class="c"># prints: “1.3027204321821337”</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>About $ 1.3 $ drinks per day, or roughly half of what I was drinking during my
two panic tracking periods. If you ask <a href="http://www.gallup.com/poll/156770/majority-drink-alcohol-averaging-four-drinks-week.aspx">Gallup</a>, though, they have a
different number: $ 4.2 / 7 = 0.6 $ drinks per day. <a href="http://pubs.niaaa.nih.gov/publications/RethinkingDrinking/Rethinking_Drinking.pdf">Rethinking Drinking</a>,
a pamphlet from the <a href="http://www.nih.gov/">National Institutes of Health</a>, provides yet another
look at drinking habits nationwide:</p>

<p><img src="https://lh3.googleusercontent.com/-vEbziueqO8I/UKQN1vuM15I/AAAAAAAAANg/ermiP-4-0oA/s800/nih-alcohol-use.jpg"></p>

<p>(This points out a general
problem with data in the social sciences. Polling and measurement methodologies
vary widely, as do the means by which data is presented.)</p>

<p>Regardless of which source I choose to believe, <em>my data still places me above
average.</em></p>

<p>There was also a more personal reason: in <a href="/blog/2012/10/09/self-tracking-for-panic-an-even-deeper-look/">analyzing the panic data</a>,
<em>I found that caffeine wasn’t the only panic-inducing culprit.</em> By training a
<a href="https://github.com/candu/quantified-savagery-files/blob/master/Panic/recovery-journal/panic_maxent.py">maximum entropy classifier</a>, I found that high alcohol consumption was
predictive of panic attacks. <a href="/blog/2012/10/08/self-tracking-for-panic-a-deeper-look/">Dissecting my data with bash</a> supported
this hypothesis: on days where I had a panic attack, I was usually drinking
more than average both that day and the previous day.</p>

<h2 id="elimination-or-moderation">Elimination Or Moderation?</h2>

<p>So why elimination instead of moderation? Simple: <em>moderation wasn’t working.</em>
I’d been using the USDA guidelines as my goal during the two panic tracking
periods, with little success.</p>

<p>(As it happens, I was also reading <a href="http://www.emptymirrorbooks.com/beat/kerouac-big-sur.html">Big Sur</a> at the time, which contains
<a href="http://www.jackkerouac.com/">Jack Kerouac’s</a> harrowing account of <a href="http://www.ncbi.nlm.nih.gov/pubmedhealth/PMH0001771/">delirium tremens</a>. This may
have provided some additional impetus in the decision!)</p>

<p>The <a href="http://strategicsimplicity.com/3-reasons-to-form-new-habits-slowly-and-how-i-failed">received wisdom</a> is that this sort of “cold turkey” habit change
usually leads to failure: willpower is finite, we burn out easily, there are
powerful social triggers, etc. Except:</p>

<p><blockquote><p>I didn’t find elimination harder. On the contrary, it was much easier than moderation.</p></blockquote></p>

<p>I didn’t stop going out to bars or visiting friends. I didn’t smash all the
bottles in the liquor cabinet or pour out the homebrew stash.
I didn’t enroll in any support groups or 12-step programs. What gives?</p>

<h2 id="willpower-endurance-versus-strength">Willpower: Endurance Versus Strength</h2>

<p>Elimination and moderation have different <em>decision-making profiles:</em></p>

<ul>
  <li><strong>Elimination:</strong> the decision is always No. This default decision is
applied to every decision instance.</li>
  <li><strong>Moderation:</strong> the decision may be Yes or No. Each decision instance
requires a consideration of the circumstances.</li>
</ul>

<p>When I attempted to apply moderation, I found myself <em>breaking down this
consideration into a complex set of rules:</em></p>

<ul>
  <li><strong>Amount:</strong> <em>Have I said Yes too much?</em></li>
  <li><strong>Cost:</strong> <em>Who pays for Yes?</em> Am I paying? Is a friend buying the next round?
Did I receive free beer in exchange for volunteer services?</li>
  <li><strong>Novelty:</strong> <em>Is this Yes different somehow?</em> Am I at a brewery I’ll likely
never visit again? Did a batch of homebrew just finish carbonation?</li>
  <li><strong>Social Pressure:</strong> <em>What are the social costs of Yes and No?</em></li>
  <li><strong>Special Occasions:</strong> <em>Does the occasion warrant changing the Yes threshold?</em>
Am I on vacation? At a fancy restaurant? Out at a concert?</li>
</ul>

<p>Taking the <a href="http://scopeblog.stanford.edu/2011/12/29/a-conversation-about-the-science-of-willpower/">willpower as muscle</a> metaphor one step further, this was
a feat of endurance. Even though amount should be the only relevant factor
here, <em>each decision instance spawned a host of smaller sub-decisions.</em></p>

<p>By contrast, the elimination strategy required only one decision for each
instance, <em>and that decision was predetermined:</em> No. It was a larger single
decision, more akin to a feat of willpower strength.</p>

<h2 id="replacing-the-routine">Replacing The Routine</h2>

<p>In <a href="http://charlesduhigg.com/">Charles Duhigg’s</a> conception of the <a href="http://charlesduhigg.com/how-habits-work/">habit loop</a>, we can’t
truly break habits; we can only <em>swap in alternate routines</em> that connect the
old cues and rewards.</p>

<p>This reminded me of a term my friend <a href="http://www.linkedin.com/pub/travis-brooks/4/668/b44">Travis Brooks</a>
used: ENAB, short for <em>Equally-attractive Non-Alcoholic Beverage.</em> There
are delicious <a href="http://shop.torani.com/Bacon-Flavored-Syrup/p/TOR-431248&amp;c=Torani@Syrups?utm_source=google&amp;utm_medium=cpc&amp;adtype=pla&amp;kw=&amp;gclid=CNL6sv21z7MCFQuCQgod-RcAgA">flavor syrups</a> and <a href="http://www.bundaberg.com/info/product_range/ginger_beer/">ginger beers</a>.
<a href="http://www.myrecipes.com/recipe/herb-infused-spa-water-10000000682668/">Spa water</a> and <a href="http://store.primowater.com/Carbonators.aspx">carbonation systems</a> lend new life to boring
<a href="http://www.dhmo.org/facts.html">dihydrogen monoxide</a>. By making non-alcoholic beverages <em>as exciting as
microbrews and Sonoma wines</em>, I tapped into my desire for exploration: here
was a whole new range of beverages to discover!</p>

<h2 id="openness-and-social-myths">Openness And Social Myths</h2>

<p>As the Alcohol Screening questionnaire said:</p>

<p><blockquote><p>Many of us think our drinking is like everyone else’s.</p></blockquote></p>

<p>While it is true that <a href="http://www.psychologytoday.com/blog/the-scientific-fundamentalist/201010/why-intelligent-people-drink-more-alcohol">more educated people drink more</a>, I
encountered much less of a “drinking culture” among my friends than
I had expected.
In fact, by being open about my behavior change and the motivations
behind it, I received a good deal of social support for this decision.</p>

<p><em>Mistaken expectations are persistent in habit change:</em></p>

<ul>
  <li><strong>Fear Of Isolation:</strong> We may believe that our current habits are
<em>normal or average</em>, and resist changing for fear of being regarded
as unusual.</li>
  <li><strong>Fear Of Inadequacy:</strong> We may believe that we are <em>unable or less
able</em> to change than others, and resist changing for fear we will
not be successful.</li>
</ul>

<p>In both cases, data to refute the fear-expectation may be hard to find.</p>

<h2 id="final-thoughts">Final Thoughts</h2>

<p>There are many ways in which my approach <em>could fail to work for others:</em></p>

<ul>
  <li><strong>Physical Dependence:</strong> Although I drank more than average, my drinking had not
progressed to the point of chronic dependence. Alcohol withdrawal
<a href="http://www.ncbi.nlm.nih.gov/pubmedhealth/PMH0001769/">can be extremely serious</a>, so this unsupervised “cold turkey”
approach might be dangerous for problem drinkers or alcoholics.</li>
  <li><strong>Social Pressure:</strong> I found my friends to be understanding of my habit
change. This is not universally true, however, and in some instances
it may be necessary to rethink your personal relationships before
behavior change can occur.</li>
  <li><strong>Specific Desires:</strong> Exploration is a strong part of my identity.
Others will have different mental cues to tackle or subvert in designing
behavior change strategies.</li>
  <li><strong>Willpower:</strong> If strength and endurance are separable components of
the “willpower muscle”, it’s possible that others may find the endurance
of many small decisions easier than the strength of one big decision.</li>
</ul>

<p>These same factors made elimination an easier form of habit change for me.
Although there are general principles of <a href="http://www.meetup.com/habitdesign/">habit design</a>, I believe that
further exploration will reveal it to be a <em>highly personal process.</em></p>

<p><blockquote><p>It is one thing to say “replace the routine”, and an entirely different thing to do so.</p></blockquote></p>

<p>This is not to say that such exploration is hopeless; far from it.
If <a href="http://quantifiedself.com/2010/12/a-futurists-take-on-self-tracking-and-mindfulness/">self-tracking leads to mindfulness</a>,
perhaps this mindfulness will equip us to <em>more effectively identify and modify
the habit loops that rule our lives.</em></p>

<h2 id="what-next">What Next?</h2>

<p>My goal is not lifelong abstinence from alcohol. Rather, I’m hoping that
this will reset my baseline consumption, making it easier to practice
moderation later.</p>

<p>This experience has also demonstrated that elimination is a
viable choice for me; if I find that my moderation efforts are slipping, I
can return to a period of elimination. Having <em>proven strategies</em>
under your belt can be enormously helpful in <em>making behavior change stick.</em></p>
]]></content>
  </entry>
  
</feed>
