<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Panic | Quantified Savagery]]></title>
  <link href="http://candu.github.com/blog/categories/panic/atom.xml" rel="self"/>
  <link href="http://candu.github.com/"/>
  <updated>2012-10-16T19:26:26-07:00</updated>
  <id>http://candu.github.com/</id>
  <author>
    <name><![CDATA[Evan Savage]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Fitbit: My Brief Experience]]></title>
    <link href="http://candu.github.com/blog/2012/10/16/fitbit-my-brief-experience/"/>
    <updated>2012-10-16T07:00:00-07:00</updated>
    <id>http://candu.github.com/blog/2012/10/16/fitbit-my-brief-experience</id>
    <content type="html"><![CDATA[<p>In this post, I discuss my experiences using the popular
<a href="http://www.fitbit.com/">Fitbit</a> fitness tracker.</p>

<!-- more -->

<h2 id="my-time-with-fitbit">My Time With Fitbit</h2>

<p>I started using the <a href="http://www.fitbit.com/product">Fitbit Ultra</a> on April 11, 2012:</p>

<p><img src="https://lh6.googleusercontent.com/-BbdI4RDLEPg/UH4U2PwH7AI/AAAAAAAAAFI/cdY5hnwl3so/s400/steps-april.jpg"></p>

<p>Over the following three months, I walked, ran, and otherwise jostled my Fitbit
about a good deal:</p>

<p><img src="https://lh6.googleusercontent.com/-Rk-sPLHtYVg/UH4U3FhjRJI/AAAAAAAAAFY/J7Ygbqqfi_k/s288/lifetime-steps.jpg">
<img src="https://lh4.googleusercontent.com/-663jKpbc6yw/UH4U3vzf8EI/AAAAAAAAAFg/-EnTuoTD9LQ/s288/lifetime-floors.jpg">
<img src="https://lh4.googleusercontent.com/-yzUccJOlbCQ/UH4U36eSCJI/AAAAAAAAAFk/Qmx-r-swHwc/s800/lifetime-distance.jpg"></p>

<p>Somewhere around July 12, tragedy struck: <em>I lost my Fitbit.</em></p>

<p><img src="https://lh3.googleusercontent.com/–zc0squq1yo/UH4U1nCGuQI/AAAAAAAAAE8/aDOP5c1f0pw/s400/steps-july.jpg"></p>

<h3 id="the-good">The Good</h3>

<p>My initial impression was ecstatic. Fitbit didn’t look like your average
pedometer:</p>

<p><img src="https://lh5.googleusercontent.com/-eLa1uqTeKRg/UH4U5G5GSNI/AAAAAAAAAF0/RiNA89GciGQ/s288/fitbit.jpg">
<img src="https://lh5.googleusercontent.com/-eRCIrQhA5Kk/UH4U1SaRsKI/AAAAAAAAAE0/4y8n3UjOl-c/s288/janky-pedometer.jpg"></p>

<p>Surround your pullquote like this {" text to be quoted "}</p>

<p><em>Wireless syncing</em> and <em>long battery life</em> sweetened the deal. This was a vast step
up from my pen-and-paper recovery journal. I was doing <em>serious</em> self-tracking
with <em>serious</em> devices now.</p>

<p>As I started to use it, I noticed <em>small changes in my behavior.</em> I’d walk an
extra few blocks to the employee shuttle. I’d buy fewer groceries at the market,
forcing myself to walk there more frequently. I’d take late-evening walks if I
felt my daily step count was too low. Each change was minor, but they often
added up to <em>thousands of additional steps per day.</em></p>

<p>I’d also revel in more extreme bursts of exercise. A hike in the Marin headlands
netted me the 30 000 step badge. I pocketed the 200 floors badge after a
<a href="http://goo.gl/maps/jB7fa">ride up to Tilden</a>.</p>

<p>For the first time, I could also see how much I was sleeping:</p>

<p><img src="https://lh6.googleusercontent.com/-QGWtSgEdMz8/UH4U5qNFyXI/AAAAAAAAAF8/5dGzfE_2YBk/s400/sleep-graph.jpg"></p>

<p><em>Great gouts of data</em> poured into my life, chartporn galore for an unrepentant 
math addict. Soon it even became a quasi-social activity as my leaderboard
filled up with my Fitbit-using friends.</p>

<p>All in all, the Fitbit seemed like a fantastic way to turbocharge my exercise
patterns.</p>

<h3 id="the-bad">The Bad</h3>

<p>My wife, <a href="http://www.eecs.berkeley.edu/~valkyrie/">Valkyrie Savage</a>, also had a Fitbit. In the instructions, women
were suggested to wear the Fitbit on their bra strap for the ultimate in
clandestine self-tracking. This soon unearthed a glaring problem:</p>

<p><blockquote><p>Sweat is corrosive to metal.</p></blockquote></p>

<p>In particular, the internal leads started to corrode, and before long she was
unable to connect it to the base station. After a quick phone call, Fitbit
agreed to replace the device at no cost; we weren’t the first users to have
this problem, and they were in the process of changing the documentation.</p>

<p>Still, the experience soured the deal a bit. Had they never field-tested it with
women?</p>

<p>While we waited for the replacement, I noticed something else: my wristband
had stretched out and was now loose on my wrist. This was a minor detail,
but it added to a growing concern that the Fitbit Ultra <em>might not be
durable enough to withstand our protracted Savage-ing.</em></p>

<p>Her second Fitbit finally arrived, and we were back into the self-tracking groove.
We took our Fitbits everywhere: walking, running, playing soccer, cycling,
and…wait, no, <em>Valkyrie couldn’t take it swimming.</em> Actually, it didn’t
measure our cycling accurately, it was useless for my static
bodyweight exercises, and it couldn’t track our occasional indoor climbing
stints effectively either. <em>It was discouraging us from doing the activities
we loved most!</em></p>

<h3 id="the-ugly">The Ugly</h3>

<p>As we kept up our co-tracking, Valkyrie and I noticed a curious effect.
There were several days where we spent the whole day together doing the
exact same things, and yet <em>I would always be 1000-2000 steps ahead.</em> Our stride lengths
and heights are nearly equal. What was going on?</p>

<p>We tried wearing the Fitbits in the same locations on our bodies. No effect.
We tried counting steps while we were out together. The counts matched up.
The solution came by accident. With the wristband getting more stretched out
by the day, I finally started taking my Fitbit off when going to bed.
going to bed.</p>

<p>Aha! There was the difference: <em>it was counting every tiny
movement I made while asleep.</em> This effect was never mentioned in the
manual. It hadn’t occurred to us that <em>our data might not be comparable!</em></p>

<p>Meanwhile, my interest in Quantified Self was gradually intensifying. I
decided to check out the <a href="http://dev.fitbit.com/">Fitbit API</a>, hoping to create something like
<a href="https://github.com/beaugunderson/zeo-crossfilter">zeo-crossfilter</a> for Fitbit.
This immediately hit a snag: <em>to get the minute-by-minute data, you need 
Partner API access.</em></p>

<p><blockquote><p>Partner API allows to fetch the intraday data points with 1 minute detail level for several user resources</p><footer><strong>Fitbit Partner API</strong> <cite><a href='https://wiki.fitbit.com/display/API/Fitbit+Partner+API'>wiki.fitbit.com/display/API/&hellip;</a></cite></footer></blockquote></p>

<p>Fortunately, <a href="http://pavelrisenberg.com/">Pavel Risenberg</a>
happily extended this access upon request, and I soon had
<a href="https://github.com/candu/fitbit-crossfilter">fitbit-crossfilter</a> up and
working.</p>

<p><img src="https://lh6.googleusercontent.com/-Ys7TdGOf2kI/UH4U6Tb2pRI/AAAAAAAAAGE/yVHssco65NU/s640/fitbit-crossfilter.jpg"></p>

<p>Again, though, there was that sour taste. <em>Why not provide this access by default?</em>
A bit of digging around the site revealed a likely culprit:
<a href="http://www.fitbit.com/premium/about">Fitbit Premium</a>.
Users can pay to turn Fitbit into a personal trainer, gaining access
to more powerful data reports and goal-setting tools.</p>

<h3 id="the-verdict">The Verdict</h3>

<p><em>Was the Fitbit useful for me?</em> As a way to encourage walking: definitely.
As a lightweight persistent self-tracking device: mostly. As part of an
exercise program that meant something to me: not really.</p>

<p>I was left with a strong suspicion that <em>I wasn’t in their target demographic.</em> I was
already fairly active. 10 000 steps was more of a baseline than a goal. I didn’t
really need to walk more, and <em>I couldn’t trust it</em> to accurately track the types
of exercise I enjoy most.</p>

<p>This is an important lesson for aspiring Quantified Self entrepreneurs:</p>

<p><blockquote><p>Your product is personal by nature.</p></blockquote></p>

<p>Your product will encounter
<a href="http://quantifiedself.com/2012/08/nir-eyal-knowing-your-behaviour-type-from-gary-wolf-on-vimeo/">different behaviors</a>,
needs, and goals. <em>You are not everyone.</em> You will never understand most of these
behaviors, needs, and goals firsthand. No amount of user studies,
A/B testing, or market research will save you from this fundamental truth.</p>

<p>The only way out is to <em>give users control.</em> Let them tinker, mashup, share,
and explore. <em>Let them decide what your product means to them.</em></p>

<h2 id="questions-from-my-time-as-a-fitbit-user">Questions From My Time As A Fitbit User</h2>

<h3 id="who-owns-self-tracking-data">Who Owns Self-Tracking Data?</h3>

<p>Surround your pullquote like this {" text to be quoted "}</p>

<p>The analogy is apt. Much as the old fiefdoms laid claim to your land and labor,
these fiefdoms <em>use your data and your data entry labor to enrich
themselves.</em> Much as the old fiefdoms provided vital services in exchange
for this taxation, you receive the <em>benefit of services like search and
social networking.</em> Much as the old fiefdoms fought each other relentlessly for
economic gain, these fiefdoms <em>wage war over users and intellectual property.</em></p>

<p>This is not necessarily bad. As a result of these data fiefdoms, we have many
services that might not otherwise exist. By selling your self-tracking data
back to you, Fitbit is <em>able to fund the provision of tools for managing and
improving your fitness.</em> Those tools are generally of reasonable quality,
and are likely to improve over time.</p>

<p>However, if you want to make your own tools, <em>you’re largely out of
luck.</em> You can pay for different tools via Fitbit Premium, but there’s no
guarantee that those tools will be better for <em>you.</em> Your only other
recourse is to navigate the API documentation and contact the right people for
better data access. Even with that access, you still only have
minute-by-minute data. You have no idea how Fitbit maps between raw
accelerometer readings and steps, and definitely no opportunity to improve that
mapping. To take my example, <em>I can’t tweak the step detection algorithms to
measure cycling accurately.</em></p>

<p>Even though the average person won’t care to make these improvements,
<em>a few people will.</em> This recalls the <a href="https://www.facebook.com/photo.php?fbid=3563106890027">reddit maxim</a>:</p>

<p><img src="https://lh6.googleusercontent.com/-Y4JWrp5wBmU/UH4U4dNSO-I/AAAAAAAAAFs/qCIibiyvafk/s400/give-a-damn.jpg"></p>

<p><em>There’s a tension here.</em> This is how better products are built, but it’s not
in Fitbit’s interest to let just anyone do that in a completely unconstrained
fashion. If they do, they go out of business.</p>

<h3 id="what-is-my-ideal-fitness-tracking-device">What Is My Ideal Fitness Tracking Device?</h3>

<p>It would be:</p>

<ol>
  <li><strong>activity-agnostic,</strong> with the ability to track diverse forms of
physical activity.</li>
  <li><strong>water-resistant.</strong> (I won’t ask for waterproof, since I’m not much of a
swimmer myself, but it should be able to handle light rain and a little
sweat.)</li>
  <li><strong>data-transparent,</strong> allowing me to get at the raw data without going
through a vendor API. (I note that <a href="https://github.com/qdot/libfitbit">libfitbit</a> exists as an
attempt to reverse-engineer Fitbit, but I haven’t played around with it.)</li>
</ol>

<p>I haven’t looked into <a href="http://www.bodymedia.com/">BodyMedia</a> or
<a href="https://fluxtream.com">Fluxtream</a>, but they both look promising.</p>

<h3 id="is-persistent-tracking-useful">Is Persistent Tracking Useful?</h3>

<p><blockquote><p>Yes, but only if you can analyze the data as quickly as you generate it.</p></blockquote></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Self-Tracking for Panic: Another Dataset]]></title>
    <link href="http://candu.github.com/blog/2012/10/14/self-tracking-for-panic-another-dataset/"/>
    <updated>2012-10-14T21:23:00-07:00</updated>
    <id>http://candu.github.com/blog/2012/10/14/self-tracking-for-panic-another-dataset</id>
    <content type="html"><![CDATA[<p>In this post, I perform the same analyses presented in
<a href="/blog/2012/10/09/self-tracking-for-panic-an-even-deeper-look/">my last post</a> using data from my second panic tracking period.
I then test whether my average alcohol and sugar consumption changed
measurably between the two tracking periods.</p>

<p>During the second tracking period, I gathered data using
<a href="https://github.com/candu/qs-counters">qs-counters</a>, a simple utility I built for reducing friction in
the recording process.</p>

<!-- more -->

<h2 id="the-usual-suspects">The Usual Suspects</h2>

<h3 id="linear-regression">Linear Regression</h3>

<p>During the second tracking period, <em>alcohol consumption remained
relatively constant</em>:</p>

<p><img src="https://lh4.googleusercontent.com/-Kha5L6BVqUo/UHxN-lFh_LI/AAAAAAAAADY/eVVLWJbYMaU/s640/qs-counters-alcohol.jpg" title="Alcohol Consumption" ></p>

<p>Sugar consumption is a different story, with a <em>pronounced negative trend</em>:</p>

<p><img src="https://lh6.googleusercontent.com/-MN60bkN-thg/UHxN_qhP-AI/AAAAAAAAADo/HXsmUbqEWnw/s640/qs-counters-sweets.jpg" title="Sugar Consumption" ></p>

<p>The evidence to suggest that <em>my alcohol and sugar consumption are linked</em> is
also much stronger now:</p>

<p><img src="https://lh5.googleusercontent.com/-9J_fMxZS2Co/UHxOAaijDbI/AAAAAAAAAD4/UDt5xjzZ-Lw/s640/qs-counters-alcohol-vs-sugar.jpg" title="Alcohol vs. Sugar Consumption" ></p>

<p>On the other hand, the previous-day alcohol effect seems to be
non-existent:</p>

<p><img src="https://lh6.googleusercontent.com/-8CPpr0mjczs/UHxOABjFKSI/AAAAAAAAADw/4sVdt2axAEs/s640/qs-counters-alcohol-today-vs-yesterday.jpg" title="Alcohol: Today vs. Yesterday" ></p>

<h3 id="fast-fourier-transform">Fast Fourier Transform</h3>

<p>With more data points, the FFT frequency amplitude plot is more muddled:</p>

<p><img src="https://lh4.googleusercontent.com/-1AeQyUEEW8o/UHxN90Wk75I/AAAAAAAAADM/eJs5x6UaQNI/s640/qs-counters-fft-frequencies.jpg" title="FFT Frequencies" ></p>

<p>The 2-day and 7-day effects previously “discovered” are nowhere to be
found.</p>

<h3 id="maximum-entropy-modelling">Maximum Entropy Modelling</h3>

<p>I didn’t record panic attacks during this tracking period. My previous
efforts reduced the severity and frequency of these attacks drastically,
enough so that the data here would have been extremely sparse.</p>

<p>In the absence of that data, I asked a different question:</p>

<p><blockquote><p>What features best predict my exercise patterns?</p></blockquote></p>

<p>Here are the top features from <code>MaxentClassifier</code>:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>3.369 caffeine==True and label is ‘no-exercise’
</span><span class='line'>  -0.739 sweets==True and label is ‘exercise’
</span><span class='line'>   0.399 sweets==True and label is ‘no-exercise’
</span><span class='line'>  -0.201 alcohol==True and label is ‘exercise’
</span><span class='line'>   0.166 alcohol==True and label is ‘no-exercise’
</span><span class='line'>   0.161 relaxation==True and label is ‘exercise’
</span><span class='line'>  -0.092 relaxation==True and label is ‘no-exercise’</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>The caffeine finding is misleading. On one of the two days where I entered
non-zero caffeine consumption, that was due to a <em>mistake in data entry.</em>
(Side note to self: all tools should include an undo feature!) Aside from
that, <em>sugar consumption appears to have the strongest negative effect on
exercise.</em></p>

<h2 id="students-t-test">Student’s t-test</h2>

<h3 id="what">What?</h3>

<p>Student’s t-test answers this question:</p>

<p><blockquote><p>Are these samples significantly different?</p></blockquote></p>

<p>More formally, the t-test answers a statistical question about normal
distributions: given
$ X \sim \mathcal{N}(\mu_X, \sigma_X^2) $ and
$ Y \sim \mathcal{N}(\mu_Y, \sigma_Y^2) $,
does $ \mu_X = \mu_Y $?</p>

<p>If we let $ Y $ be a known normal distribution centered at
rather than taking it from an empirical sample,
we also obtain a one-sample t-test for the null hypothesis
$ \mu_X = \mu_Y $.</p>

<h3 id="why">Why?</h3>

<p>In a self-tracking context, you might ask the following questions:</p>

<ul>
  <li>Did I improve significantly across tracking periods?</li>
  <li>Is my behavior consistent across tracking periods?</li>
</ul>

<p>Student’s t-test can help address both questions.</p>

<h3 id="the-data">The Data</h3>

<p>Before using Student’s t-test on my alcohol and sugar consumption data from
the two tracking periods, I <em>check whether these samples have a roughly
normal distribution.</em> The code for normality checking is
<a href="https://github.com/candu/quantified-savagery-files/blob/master/Panic/qs-counters/counters_normality.py">here</a>.</p>

<p>It helps to <em>visualize the histogram data first</em>:</p>

<p><img src="https://lh5.googleusercontent.com/-1sX3PJfuiAg/UHxdvv_-mkI/AAAAAAAAAEc/Rm7uknNlG7g/s640/recovery-journal-alcohol-histogram.jpg" title="Alcohol Histogram (recovery-journal)" >
<img src="https://lh5.googleusercontent.com/-9ScCbHMq4ls/UHxdu40NnPI/AAAAAAAAAEM/3SRyqPF_Bh8/s640/qs-counters-alcohol-histogram.jpg" title="Alcohol Histogram (qs-counters)" ></p>

<p><img src="https://lh3.googleusercontent.com/-10RnNsKZAS0/UHxdvzkHVhI/AAAAAAAAAEg/QCgl_8vd4Go/s640/recovery-journal-sweets-histogram.jpg" title="Sugar Histogram (recovery-journal)" >
<img src="https://lh6.googleusercontent.com/-c407cdWckp0/UHxdvMT5GJI/AAAAAAAAAEU/_xR3qO3ZMX0/s640/qs-counters-sweets-histogram.jpg" title="Sugar Histogram (qs-counters)" ></p>

<p>These don’t look particularly close to normal distributions, but it’s hard to
tell with discrete-valued data. For more evidence, I use the
<a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html">Shapiro-Wilk statistical normality test</a>:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>alcohol, recovery-journal:  (0.944088339805603, 0.10709714889526367)
</span><span class='line'>alcohol, qs-counters:  (0.8849299550056458, 4.6033787270971516e-07)
</span><span class='line'>sugar, recovery-journal:  (0.722859263420105, 2.5730114430189133e-06)
</span><span class='line'>sugar, qs-counters:  (0.8092769384384155, 8.38931979441071e-10)</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>The null hypothesis for Shapiro-Wilk is that the sample is normally distributed,
so these low p-values indicate the opposite: <em>my data isn’t normally distributed!</em>
Bad news for my attempt to use Student’s t-test here.</p>

<p>Nevertheless, I’ll barge ahead and run the t-test anyways, just to see what
that process looks like with <code>scipy.stats</code>. The code for t-testing is
<a href="https://github.com/candu/quantified-savagery-files/blob/master/Panic/qs-counters/counters_ttest.py">here</a>.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>alcohol
</span><span class='line'>==========
</span><span class='line'>avg(A) = 3.26
</span><span class='line'>avg(B) = 2.35
</span><span class='line'>(t, p) = (2.0721, 0.0469)&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;h1 id="sweets">sweets&lt;/h1>
</span><span class='line'>&lt;p>avg(A) = 1.19
</span><span class='line'>avg(B) = 1.23
</span><span class='line'>(t, p) = (-0.1969, 0.8453)</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>If the t-test were useful for this data, it would show that <em>my alcohol
consumption was significantly lower during the second tracking period.</em>
With such a large drop in average consumption, I’m willing to say that
this is a reasonable assertion.</p>

<h2 id="a-question-of-motivation">A Question Of Motivation</h2>

<p>By this point, you might be asking:</p>

<p><blockquote><p>Why did I even bother with all this analysis when I have so few data points?</p></blockquote></p>

<p>Good question! The short answer? It’s a <em>learning opportunity.</em> The longer
answer is backed by a chain of reasoning:</p>

<ul>
  <li>As data collection gets easier, <em>the value of data analysis goes up;</em></li>
  <li>Statistical analysis is <em>hard to impossible</em> for the average user, so <em>they
will use whatever tools they can get</em> from app markets and device vendors;</li>
  <li>Most of those tools are built by people who, by trade, are software
developers;</li>
  <li>Most developers, even good ones, are typically not that great in the
statistics and data analysis department;</li>
  <li>Therefore, as a developer with plans to build self-tracking tools, <em>I owe it
to myself and my future users to know this stuff better.</em></li>
</ul>

<p>As it turns out, data analysis is hard, period. Picking the right tools is
difficult, and picking the wrong ones (like the t-test above!) <em>can easily
produce results that appear to be meaningful but are not.</em> In a self-tracking
scenario, this problem is often made worse by <em>smaller datasets</em> and <em>uncontrolled
conditions.</em></p>

<h2 id="thought-experiments">Thought Experiments</h2>

<h3 id="repeat-yourself-a-reflection-on-self-tracking-and-science">Repeat Yourself: A Reflection On Self-Tracking And Science</h3>

<p>One criticism often launched at the Quantified Self community is that
self-tracking is not <em>scientific</em> enough. For an interesting discussion
of the merits and drawbacks of presenting self-experimentation as science,
I highly recommend the <a href="http://www.escholarship.org/uc/item/2xc2h866#page-36">Open Peer Commentary section</a>
of <a href="http://www.escholarship.org/uc/item/2xc2h866">this paper</a>. Some of
the broader themes in this debate are also summarized
<a href="http://quantifiedself.com/2012/05/qs-101-the-science-of-self-experimentation/">here</a> on
the Quantified Self website.</p>

<p>To be fair, there are a host of valid concerns here. For starters,
<em>it’s very difficult to impose a controlled environment when self-tracking.</em>
In a Heisenbergian twist, being mindful of your behavior could modify the
behavior you’re trying to measure; this effect is discussed briefly by
<a href="http://www.escholarship.org/uc/item/2xc2h866#page-45">Simon Moore and Joselyn Sellen</a>.</p>

<p>Additionally, a sample population of one is meaningless. Will your
approaches work for others? Did you gather the data in a consistent
manner? Are your sensors working properly? The usual antidote is to
increase the sample population, but then you have another set of problems.
Are all participants using the same sensors in the same way? Are they all
running the same analyses?</p>

<p>From watching several presentations about self-tracking, there is a
curious pattern:</p>

<p><blockquote><p>Like any other habit, the tracking habit is hard to maintain.</p></blockquote></p>

<p>As a corollary, many tracking experiments consist of multiple
tracking periods, these punctuated by relapses of the tracking habit.</p>

<p>Many people interpret these relapses as failures, but they’re actually
<em>amazing scientific opportunities!</em> These are chances to re-run the same
experiment, verifying or confounding results from your earlier tracking
periods.</p>

<h3 id="the-predictive-modelling-game">The Predictive Modelling Game</h3>

<p>Predictive modelling could be an interesting component of a habit
modification system. Suppose I want to exercise more regularly. First, 
I <em>select several features that seem likely to influence my exercise
patterns</em>, such as:</p>

<ul>
  <li>Am I travelling? Where am I?</li>
  <li>What foods did I eat? When? How much?</li>
  <li>How positive or negative is my mood?</li>
  <li>Did I schedule time today to exercise?</li>
  <li>Did I exercise yesterday? How much?</li>
</ul>

<p>Next, I <em>gather some baseline data</em> by tracking these features along with
my exercise patterns. I then use that data to <em>train a classifier.</em>
Finally, I keep tracking the features, ask the classifier to predict my
exercise activity, and play a simple game with myself:</p>

<p><blockquote><p>Can I beat the classifier?</p></blockquote></p>

<p>That is, <em>can I exercise more often than my existing behavior patterns
suggest I should?</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Self-Tracking For Panic: A Deeper Look]]></title>
    <link href="http://candu.github.com/blog/2012/10/09/self-tracking-for-panic-an-even-deeper-look/"/>
    <updated>2012-10-09T07:00:00-07:00</updated>
    <id>http://candu.github.com/blog/2012/10/09/self-tracking-for-panic-an-even-deeper-look</id>
    <content type="html"><![CDATA[<p>In this post, I apply three statistical and machine learning tools to my panic
recovery journal data: linear regression/correlation, the Fast Fourier
Transform, and maximum entropy modelling.</p>

<!-- more -->

<h2 id="first-a-word-about-tools">First, A Word About Tools</h2>

<p><blockquote><p>I suppose it is tempting, if the only tool you have is a hammer, to treat<br/>everything as if it were a nail.</p><footer><strong>Abraham Maslow</strong> <cite>The Psychology of Science: A Reconnaissance</cite></footer></blockquote></p>

<h2 id="now-a-necessary-disclaimer">Now, A Necessary Disclaimer</h2>

<p>My experiment has fewer than 50 samples, which is <em>nowhere near enough to draw
statistically significant conclusions</em>. That’s not the point. The primary
purpose of this post is to <em>demonstrate analysis techniques by example</em>. These
same methods can be wielded on larger datasets, where they are much more
useful.</p>

<h2 id="getting-ready">Getting Ready</h2>

<p>To follow along with the examples here, you’ll need
the excellent Python toolkits
<a href="http://scipy.org/">scipy</a>,
<a href="http://matplotlib.org/">matplotlib</a>, and
<a href="http://nltk.org/">nltk</a>:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ pip install scipy nltk matplotlib</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h2 id="linear-regression">Linear Regression</h2>

<h3 id="what">What?</h3>

<p>Linear regression answers this question:</p>

<p><blockquote><p>What is the line that most closely fits this data?</p></blockquote></p>

<p>Given points $ P_i = (x_i, y_i) $, the goal is to find the line
$ y = mx + b $ such that some error function is minimized.
A common one is the least squares function:</p>

<script type="math/tex; mode=display">
f(m, b) = \sum_{i} \left(y_i - (mx_i + b)\right)^2
</script>

<p>The
<a href="http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient">Pearson correlation coefficient</a> $ R $ and
<a href="http://www.lstr.net/blog/2008/07/08/p-values-explained-well/">p-value</a> $ p $
are also useful here, as they measure <em>correlation</em> and <em>statistical
significance</em>.</p>

<h3 id="why">Why?</h3>

<p>In a self-tracking context, you might ask the following questions:</p>

<ul>
  <li>Have I been exercising more over time?</li>
  <li>Does exercise affect mood? By how much and in what direction?</li>
</ul>

<p>Linear regression can help address both questions. However, it can only find
<em>linear</em> relationships between datasets. Many dynamic processes are <em>locally linear</em>
but not <em>globally linear</em>. For instance, there are practical limits to how
much you can exercise in a day, so no linear model with non-zero slope will
accurately capture your exercise duration for all time.</p>

<h3 id="the-data">The Data</h3>

<p>You can see the code for this analysis <a href="https://github.com/candu/quantified-savagery-files/blob/master/Panic/recovery-journal/food_linregress.py">here</a>. I look at only the first
31 days, that being the largest consecutive run for which I have data.</p>

<p><img src="https://lh6.googleusercontent.com/-plD2webhfrY/UHXc4xHxAGI/AAAAAAAAACM/2X488DqHKms/s640/alcohol.jpg" title="Alcohol Consumption" ></p>

<p>My alcohol consumption did not decrease over time, but rather stayed fairly
constant: with $ R = 0.0098 $, there is no correlation between alcohol and time.</p>

<p><img src="https://lh5.googleusercontent.com/-UCZKlx5l5RI/UHXc6u8h2vI/AAAAAAAAACs/CWcJjS09dS8/s640/sweets.jpg" title="Sugar Consumption" ></p>

<p>Sugar consumption is a similar story: although the best-fit slope is slightly
negative, $ R = -0.0671 $ indicates no correlation over time. It seems that my
alcohol and sugar consumption were not modified significantly over the tracking
period.</p>

<p><img src="https://lh5.googleusercontent.com/-Ssz89uoE-EA/UHXc5DvHf0I/AAAAAAAAACU/o0C_PJpmZcM/s640/alcohol-and-sugar.jpg" title="Alcohol and Sugar Consumption" ></p>

<p>I decided to graph alcohol and sugar together. It looks like they might be
related, as the peaks in each seem to coincide on several occasions. Let’s
test this hypothesis:</p>

<p><img src="https://lh6.googleusercontent.com/-iCO9umA8L8s/UHXc5vImvhI/AAAAAAAAACc/d82SCqFs-qI/s640/alcohol-today-vs-yesterday.jpg" title="Alcohol vs. Sugar Consumption" ></p>

<p>The positive slope is more pronounced this time, but
$ R = 0.1624 $ still indicates a small degree of correlation. We can also look
at the p-value: with $ p = 0.3827 $, it is fairly easy to write this off as
a random effect.</p>

<p>Finally, let’s take another look at a question from
<a href="/blog/2012/10/08/self-tracking-for-panic-a-deeper-look/">a previous blog post</a>:</p>

<p><blockquote><p>On days where I drink heavily, do I drink less the day after?</p></blockquote></p>

<p><img src="https://lh6.googleusercontent.com/-iCO9umA8L8s/UHXc5vImvhI/AAAAAAAAACc/d82SCqFs-qI/s640/alcohol-today-vs-yesterday.jpg" title="Alcohol Consumption: Today vs. Yesterday" ></p>

<p>There’s a negative slope there, but the correlation and p-value statistics are
in the same uncertain zone as before. I likely need more data to investigate
these last two effects properly.</p>

<h2 id="fast-fourier-transform">Fast Fourier Transform</h2>

<h3 id="what-1">What?</h3>

<p>Fourier analysis answers this question:</p>

<p><blockquote><p>What frequencies comprise this signal?</p></blockquote></p>

<p>Given a sequence $ x_n $, a
<a href="http://en.wikipedia.org/wiki/Discrete_Fourier_transform">Discrete Fourier Transform</a> (DFT)
computes</p>

<script type="math/tex; mode=display">
X_k = \sum_{n=0}^{N-1} x_n \cdot e^{\frac{-2 i \pi k n}{N}}
</script>

<p>The $ X_k $ encode the amplitude and phase of frequencies
$ \frac{f k}{N} $ Hz, where $ T $ is the time between samples
and $ f = 1 / T $ is the sampling frequency.</p>

<p>As described here, the DFT requires $ \mathcal{O}(N^2) $ time to
compute. The <a href="http://mathworld.wolfram.com/FastFourierTransform.html">Fast Fourier Transform</a> (FFT) uses
divide-and-conquer on this sum of complex exponentials to compute the DFT in
$ \mathcal{O}(N \log N) $ time. 
<a href="http://groups.csail.mit.edu/netmit/sFFT/">Further speedups are possible</a> for
real-world signals that are sparse in the frequency domain.</p>

<h3 id="why-1">Why?</h3>

<p>In a self-tracking context, you might ask the following questions:</p>

<ul>
  <li>Do I have regular exercising patterns?</li>
  <li>Do these patterns cycle weekly? bi-weekly? monthly?</li>
  <li>How much does my amount of exercise fluctuate during a cycle?</li>
</ul>

<p>With the FFT, Fourier analysis can help address these questions. However, it
can only find <em>periodic</em> effects. Unlike linear regression, it does not help
find <em>trends</em> in your data.</p>

<h3 id="the-data-1">The Data</h3>

<p>You can see the code for this analysis <a href="https://github.com/candu/quantified-savagery-files/blob/master/Panic/recovery-journal/food_fft.py">here</a>. Again, I look at the
first 31 days to ensure that the frequency analysis is meaningful.</p>

<p><img src="https://lh5.googleusercontent.com/-8j00ob_Ji-Y/UHXc67MQVpI/AAAAAAAAAC0/n3akVSjtRHs/s640/fft-frequencies.jpg" title="Frequency Strengths" ></p>

<p>There are some apparent maxima there, but it’s hard to tell what they
mean. Part of the difficulty is that <em>these are frequencies rather than
period lengths</em>, so let’s deal with that:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ python food_fft.py 
</span><span class='line'>food_fft.py:32: RuntimeWarning: divide by zero encountered in divide
</span><span class='line'>  for strength, phase, period in sorted(zip(FS, FP, 1.0 / Q))[-5:]:
</span><span class='line'>[2.21 days] 3.0461 (phase=-0.67 days)
</span><span class='line'>[-2.21 days] 3.0461 (phase=-0.67 days)
</span><span class='line'>[7.75 days] 3.1116 (phase=-3.67 days)
</span><span class='line'>[-7.75 days] 3.1116 (phase=-3.67 days)
</span><span class='line'>food_fft.py:33: RuntimeWarning: invalid value encountered in double_scalars
</span><span class='line'>  phase_days = period * (phase / (2.0 * math.pi))
</span><span class='line'>[inf days] 18.1401 (phase=nan days)</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>If you’re not familiar with the Fourier transform,
the last line might be a bit mysterious. That corresponds to $ X_0 $, which
is just the sum of the original samples:</p>

<script type="math/tex; mode=display">
X_0 = \sum_{n=0}^{N-1} x_n \cdot e^0 = \sum_{n=0}^{N-1} x_n
</script>

<p>Other than that, the most pronounced cycles have period lengths of
2.21 days and 7.75 days. The former might be explained by a <em>see-saw drinking
pattern</em>, whereas the latter is likely related to the day-of-week effects
we saw <a href="/blog/2012/10/08/self-tracking-for-panic-a-deeper-look/">in the previous post</a>.</p>

<p>Which day of the week? The phase is -3.67 days, and our sample starts on a
Monday, placing the first peak on Thursday. The period is slightly longer than
a week, though, and the data runs for 31 days, so these peaks gradually shift
to <em>cover the weekend</em>.</p>

<p>There are two caveats:</p>

<ol>
  <li>I have no idea whether a Fourier coefficient of about 3 is significant
here. If it isn’t, I’m grasping at straws.</li>
  <li>Again, the small amount of data means the frequency domain data is sparse.
To accurately test for bi-daily or weekly effects, I <em>need more
fine-grained period lengths.</em></li>
</ol>

<h2 id="maximum-entropy-modelling">Maximum Entropy Modelling</h2>

<h3 id="what-2">What?</h3>

<p>Maximum entropy modelling answers this question:</p>

<p><blockquote><p>Given observations of a random process, what is the most likely model<br/>for that random process?</p></blockquote></p>

<p>Given a discrete probability distribution $ p(X = x_k) = p_k $, the entropy
of this distribution is given by</p>

<script type="math/tex; mode=display">
H(p) = \sum - p_k \log p_k
</script>

<p>(Yes, I’m conflating the concepts of
<a href="http://en.wikipedia.org/wiki/Random_variable">random variables</a> and
<a href="http://en.wikipedia.org/wiki/Probability_distribution">probability distributions</a>.
If you knew that, you probably don’t need this explanation.)</p>

<p>This can be thought of as the <em>number of bits needed to encode outcomes
in this distribution</em>. For instance, if I have a double-headed coin, I need
no bits: I already know the outcome. Given a fair coin, though, I need one bit:
heads or tails?</p>

<p>After repeated sampling, we get observed expected values for $ p_k $;
let these be $ p’_k $. Since we would like the model to <em>accurately
reflect what we already know</em>, we impose the constraints $ p_k = p’_k $.
The maximum entropy model is the model that also maximizes $ H(p’) $.</p>

<p>This model encodes what is known
<em>while remaining maximally noncommittal on what is unknown.</em></p>

<p>Adam Berger (CMU) provides <a href="http://www.cs.cmu.edu/afs/cs/user/aberger/www/html/tutorial/node2.html#SECTION00011000000000000000">a more concrete example</a>.
If you’re interested in learning more, his tutorial is highly recommended
reading.</p>

<h3 id="why-2">Why?</h3>

<p>In a self-tracking context, you might ask the following questions:</p>

<ul>
  <li>Which treatments have the greatest effect in preventing panic attacks?
Which have the least effect?</li>
  <li>Today I exercised for at least 30 minutes and had four drinks. Am I
likely to get a panic attack?</li>
  <li>What treatments should I try next?</li>
</ul>

<p>Maximum entropy modelling can help address these questions. It is often
used to <em>classify unseen examples</em>, and would be fantastic in a
<a href="http://100plus.com/2012/09/qs-data-commons/">data commons</a> scenario
with enough data to provide recommendations to users. </p>

<h3 id="feature-extraction">Feature Extraction</h3>

<p>Since I’m now effectively building a classifier, there’s an additional step.
I need features for my classifier, which I extract from my existing datasets:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>train_set = []
</span><span class='line'>dates = set(W).intersection(F)
</span><span class='line'>for ds in dates:
</span><span class='line'>  try:
</span><span class='line'>    ds_data = {
</span><span class='line'>      ‘relaxation’ : bool(int(W[ds][‘relaxation’])),
</span><span class='line'>      ‘exercise’ : bool(int(W[ds][‘exercise’])),
</span><span class='line'>      ‘caffeine’ : int(F[ds][‘caffeine’]) &gt; 0,
</span><span class='line'>      ‘sweets’ : int(F[ds][‘sweets’]) &gt; 1,
</span><span class='line'>      ‘alcohol’ : int(F[ds][‘alcohol’]) &gt; 4,
</span><span class='line'>      ‘supplements’ : bool(int(F[ds][‘supplements’]))
</span><span class='line'>    }
</span><span class='line'>  except (ValueError, KeyError):
</span><span class='line'>    continue
</span><span class='line'>  had_panic = P.get(ds) and ‘panic’ or ‘no-panic’
</span><span class='line'>  train_set.append((ds_data, had_panic))</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Note that the features listed here are binary. I use my daily goals as
thresholds on caffeine, sweets, and alcohol.</p>

<p>(If you know how to get float-valued features working with NLTK, let me know!
Otherwise, there’s always <a href="http://www.cs.utah.edu/~hal/megam/">megam</a> or
<a href="http://www-i6.informatik.rwth-aachen.de/web/Software/YASMET.html">YASMET</a>.</p>

<h3 id="the-data-2">The Data</h3>

<p>You can see the code for this analysis <a href="https://github.com/candu/quantified-savagery-files/blob/master/Panic/recovery-journal/panic_maxent.py">here</a>.
This time I don’t care about having consecutive dates, so I use all of the
samples.</p>

<p>After building a <code>MaxentClassifier</code>, I print out the most informative features
with <code>show_most_informative_features()</code>:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-2.204 exercise==True and label is ‘panic’
</span><span class='line'>   1.821 caffeine==True and label is ‘panic’
</span><span class='line'>  -0.867 relaxation==True and label is ‘panic’
</span><span class='line'>   0.741 alcohol==True and label is ‘panic’
</span><span class='line'>  -0.615 caffeine==True and label is ‘no-panic’
</span><span class='line'>  -0.537 supplements==True and label is ‘panic’
</span><span class='line'>   0.439 sweets==True and label is ‘panic’
</span><span class='line'>   0.430 exercise==True and label is ‘no-panic’
</span><span class='line'>   0.284 relaxation==True and label is ‘no-panic’
</span><span class='line'>   0.233 supplements==True and label is ‘no-panic’</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Exercise, relaxation breathing, and vitamin supplements help with panic.
Caffeine, alcohol, and sweets do not. I knew that already, but this suggests 
<em>which treatments or dietary factors have greatest impact.</em></p>

<p>Let’s consider the supplements finding more closely. Of the 45 days, I took
supplements on all but two. It’s <em>dangerous</em> to draw any conclusions from a
feature for which there are very few negative samples.
This points out some important points about data analysis:</p>

<ul>
  <li><strong>Know your data</strong>: otherwise, you may <em>ascribe undue meaning to outliers or noise.</em></li>
  <li><strong>Know your features:</strong> supplements are probably not a good feature here.
A <em>feature inclusion threshold</em> on number of positive and negative samples 
might be helpful here.</li>
  <li><strong>Beware magic:</strong> even when you understand their inner workings, <em>machine
learning algorithms can produce results that are difficult to interpret.</em></li>
</ul>

<h2 id="up-next">Up Next</h2>

<p>In my next post, I look at a panic recovery dataset gathered using
<a href="https://github.com/candu/qs-counters">qs-counters</a>, a simple utility I built to reduce friction in
self-tracking. I perform these same three analyses on the
<a href="https://github.com/candu/quantified-savagery-files/tree/master/Panic/qs-counters">qs-counters dataset</a>, then compare it to the
<a href="https://github.com/candu/quantified-savagery-files/tree/master/Panic/recovery-journal">recovery-journal dataset</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Self-Tracking For Panic: A bash-ful Look At Some Data]]></title>
    <link href="http://candu.github.com/blog/2012/10/08/self-tracking-for-panic-a-deeper-look/"/>
    <updated>2012-10-08T10:00:00-07:00</updated>
    <id>http://candu.github.com/blog/2012/10/08/self-tracking-for-panic-a-deeper-look</id>
    <content type="html"><![CDATA[<p>In this post, I perform initial exploratory analysis on my panic recovery
journal data using basic UNIX/bash commands.</p>

<!-- more -->

<h2 id="unix-bash-youre-not-serious-right">UNIX? bash? You’re not serious, right?</h2>

<p>Most of the data-centric Quantified Self talks I’ve seen focus on more
complicated methods, including:</p>

<ul>
  <li><a href="http://en.wikipedia.org/wiki/Linear_regression">linear regression</a>, which <em>identifies gradual trends</em>;</li>
  <li><a href="http://en.wikipedia.org/wiki/Fast_Fourier_transform">FFT</a>, which <em>identifies periodic effects</em>;</li>
  <li><a href="http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient">Pearson’s r</a>, which <em>measures correlation between datasets</em>;</li>
  <li><a href="http://en.wikipedia.org/wiki/Student's_t-test">t-test</a>, which <em>measures difference between datasets</em>.</li>
</ul>

<p>These are extremely powerful tools to have at your disposal. Better yet,
many languages have community-contributed libraries that provide these
tools out-of-the-box. For instance, Python’s <a href="LINK">scipy</a>
offers <a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html">linregress</a>
for performing linear regression.</p>

<p>That said, these tools rely on mathematics that is <em>opaque</em> to many software
developers. Even if you don’t need to know how they work to use them, you need
some knowledge of <em>what they do</em> and <em>where they are most appropriate</em>.
Statistical tests in particular often have <em>strong preconditions</em> for use:</p>

<p><blockquote><p>Each of the two populations being compared should follow a normal distribution.</p><footer><strong>Wikipedia</strong> <cite><a href='http://en.wikipedia.org/wiki/Student%27s_t-test'>Student’s T-test</a></cite></footer></blockquote></p>

<p>Even if you pick the right tool, there’s still <em>fear associated with losing
control</em>. These tools are not hammers and screwdrivers but magic
wands, and <a href="http://www.flickr.com/photos/wishingline/7162517642/">we are terrible magicians</a>.</p>

<h3 id="a-word-on-exploratory-analysis">A Word On Exploratory Analysis</h3>

<p>I mentioned that this post would demonstrate <em>exploratory analysis</em>. This is
a mode of analysis where you explore your data, play around with it a bit,
grab some low-hanging analytical fruit. You don’t necessarily need higher
mathematics. Regular counts and averages will do. You’re not looking for
ironclad proof, but rather for <em>suggestions</em>.</p>

<p><blockquote><p>What does this data suggest?</p></blockquote></p>

<p>This is an important question. Put this way, <em>there is no “right” or “wrong”
way to analyze your data</em>. UNIX tools fit in nicely here, because you can
piece them together and pretty quickly get some useful insights. Better yet,
since you understand what you just did, you can explain it to someone else.
Analysis becomes a <em>demystified</em> and <em>shareable</em> process.</p>

<p>Exploratory analysis is also a <em>great entry point</em> to deeper and more directed
analysis. As you work with the data, you ask more complicated questions. Eventually these
questions exceed the sophistication of your tools, so you look for better
tools. You might not deeply understand the better tools, but at least you’ve
worked with the data a bit. You can <em>perform basic sanity checks</em> when these
better tools turn up results you don’t expect.</p>

<h2 id="the-data">The Data</h2>

<p>I took my paper recovery journal logs:</p>

<p><img src="https://lh6.googleusercontent.com/-TDKFRsDfutE/UHNEPJReCOI/AAAAAAAAABU/q0sWUwRbPoE/s640/IMG<em>20121005</em>171146_426.jpg" title="A page from my journal" ></p>

<p>and manually converted them to handy CSV files:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>date,relaxation,exercise,diet,supplements
</span><span class='line'>…
</span><span class='line'>2012-03-12,0,0,1,1
</span><span class='line'>2012-03-13,1,0,1,1
</span><span class='line'>2012-03-14,1,0,0,1
</span><span class='line'>2012-03-15,1,1,1,1
</span><span class='line'>2012-03-16,1,1,1,1
</span><span class='line'>2012-03-17,1,1,0,1
</span><span class='line'>2012-03-18,0,1,0,1
</span><span class='line'>…</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Where did all those different treatments go? I didn’t end up using most of
them. Making nine parallel habit changes is difficult, so I rapidly converged
on a subset of four:</p>

<ul>
  <li>relaxation breathing;</li>
  <li>daily exercise;</li>
  <li>dietary modifications; and</li>
  <li>vitamin supplements.</li>
</ul>

<p>Why manual input? There wasn’t enough data to make
<a href="http://code.google.com/p/tesseract-ocr/">OCR</a>
worthwhile:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cd recovery-journal
</span><span class='line'>$ wc -l * | grep total
</span><span class='line'>      41 exercise-record
</span><span class='line'>      46 food-diary
</span><span class='line'>       8 panic-log
</span><span class='line'>      46 weekly-practice-record
</span><span class='line'>     141 total</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>You can view and download the raw data files
<a href="https://github.com/candu/quantified-savagery-files/tree/master/Panic/recovery-journal">here</a>.</p>

<h2 id="common-operations">Common Operations</h2>

<p>These operations appear several times in the UNIX one-liners below, so let’s go over
them quickly.</p>

<p>To lop off the CSV column name header:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>tail -n+2</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>To extract field <span>$ n $</span> from a CSV file:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cut -d’,’ -f$n</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>To tabulate counts in descending order:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sort | uniq -c | sort -rn</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>To sum a series of numbers:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>awk ‘{sum+=$1} END {print sum}’</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>To get the day before <code>$ds</code>:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ts=$(date -j -f “%Y-%m-%d” $ds “+%s”); tsprev=$(echo “$ts - 86400” | bc); dsprev=$(date -j -f “%s” $tsprev “+%Y-%m-%d”);</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h2 id="and-now-the-main-show">And Now, The Main Show</h2>

<p>Let’s start by looking at my weekly practice record:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ for a in [01] 1; do for b in [01] 1; do for c in [01] 1; do for d in [01] 1; do count=$(grep -E “,$a,$b,$c,$d$” weekly-practice-record | wc -l); echo $a $b $c $d $count; done; done; done; done | tr ‘ ‘ ‘\t’
</span><span class='line'>[01]    [01]    [01]    [01]    45
</span><span class='line'>[01]    [01]    [01]    1       43
</span><span class='line'>[01]    [01]    1       [01]    22
</span><span class='line'>[01]    [01]    1       1       21
</span><span class='line'>[01]    1       [01]    [01]    32
</span><span class='line'>[01]    1       [01]    1       31
</span><span class='line'>[01]    1       1       [01]    16
</span><span class='line'>[01]    1       1       1       16
</span><span class='line'>1       [01]    [01]    [01]    36
</span><span class='line'>1       [01]    [01]    1       34
</span><span class='line'>1       [01]    1       [01]    19
</span><span class='line'>1       [01]    1       1       18
</span><span class='line'>1       1       [01]    [01]    26
</span><span class='line'>1       1       [01]    1       25
</span><span class='line'>1       1       1       [01]    14
</span><span class='line'>1       1       1       1       14</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>I tracked myself for 45 days. During that time, I followed all four treatments
on 14 days. In order from most to least regular:</p>

<ul>
  <li>vitamin supplements (43 days);</li>
  <li>relaxation breathing (36 days);</li>
  <li>daily exercise (32 days);</li>
  <li>dietary modifications (22 days).</li>
</ul>

<p>I followed both the exercise and diet treatments for only 16 of 45 days! Right away, I
have a question for further inquiry:</p>

<p><blockquote><p>What was so hard about those two treatments?</p></blockquote></p>

<h3 id="exercise">Exercise</h3>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tail -n+2 exercise-record | cut -d’,’ -f2 | sort | uniq -c | sort -rn | head -5
</span><span class='line'>  11 16:00
</span><span class='line'>   8 20:00
</span><span class='line'>   3 15:00
</span><span class='line'>   3 14:00
</span><span class='line'>   3 12:00</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>My most common exercise times were 4pm and 8pm. What was I doing at those times?</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ grep 16:00 exercise-record | cut -d’,’ -f3 | sort | uniq -c | sort -rn | head -1
</span><span class='line'>   9 conditioning
</span><span class='line'>$ grep 20:00 exercise-record | cut -d’,’ -f3 | sort | uniq -c | sort -rn | head -1
</span><span class='line'>   6 soccer</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Aha! 4pm was my scheduled gym time at work, and 8pm was when I went for
<a href="http://soccerfours.com/">weekly pickup soccer</a>. Both were regularly scheduled activities.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ grep -E “(00|01|02|03|04|05|06|07|08|09|10|11):00” exercise-record | wc -l
</span><span class='line'>       7
</span><span class='line'>$ grep -E “(12|13|14|15|16|17|18|19|20|21|22|23):00” exercise-record | wc -l
</span><span class='line'>       33</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>I rarely exercise in the morning, which might be okay: physical performance is
<a href="http://online.wsj.com/article/SB10000872396390444180004578018294057070544.html">higher in the afternoon</a>.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tail -n+2 exercise-record | cut -d’,’ -f3 | sort | uniq -c | sort -rn
</span><span class='line'>  15 conditioning
</span><span class='line'>   7 soccer
</span><span class='line'>   6 walking
</span><span class='line'>   6 cycling
</span><span class='line'>   2 running
</span><span class='line'>   2 dancing
</span><span class='line'>   1 swimming
</span><span class='line'>   1 longboarding</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>It’s not surprising to see gym conditioning sets and soccer as my top
activities, but walking and cycling aren’t far behind.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tail -n+2 exercise-record | cut -d’,’ -f4 | sort | uniq -c | sort -rn
</span><span class='line'>  20 30
</span><span class='line'>  11 60
</span><span class='line'>   4 45
</span><span class='line'>   2 40
</span><span class='line'>   2 240
</span><span class='line'>   1 120</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>I most commonly exercised for 30-60 minutes, with infrequent longer blocks
of activity. What was I doing in those longer blocks?</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ grep -E “,(120|240)$” exercise-record 
</span><span class='line'>2012-01-27,20:00,dancing,120
</span><span class='line'>2012-01-29,10:00,walking,240
</span><span class='line'>2012-02-11,12:00,walking,240</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>When else was I dancing?</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ grep dancing exercise-record
</span><span class='line'>2012-01-27,20:00,dancing,120
</span><span class='line'>2012-02-03,21:00,dancing,30</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Looking at my calendar, these blocks are easily identified:</p>

<p><img src="https://lh6.googleusercontent.com/-BMXU2Ek3Ng0/UHNJnPz-bqI/AAAAAAAAABw/3vSmmAKQzQo/s800/Screen%2520Shot%25202012-10-08%2520at%25205.45.17%2520PM.jpg" title="Jan 27, 2012" >
<img src="https://lh4.googleusercontent.com/-EWShEmAoYPc/UHNJnuc6eGI/AAAAAAAAAB4/nWSI-zqtp_U/s800/Screen%2520Shot%25202012-10-08%2520at%25205.45.37%2520PM.jpg" title="Feb 03, 2012" ></p>

<p>Having fun is great for my health!</p>

<h3 id="diet">Diet</h3>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ for i in $(seq 2 5); do count=$(cut -d’,’ -f$i food-diary | awk ‘{ sum+=$1} END {print sum}’); name=$(head -1 food-diary | cut -d’,’ -f$i); printf “%12s\t%s\n” $name $count; done
</span><span class='line'>    caffeine    6
</span><span class='line'>      sweets    48
</span><span class='line'>     alcohol    140
</span><span class='line'> supplements    42</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>I nearly eliminated caffeine during this period! By the time I started keeping the log,
I’d already started to reduce my consumption. On average, I had just over one sweet per day.
More troubling is alcohol, with an average of 3.1 drinks/day. Let’s take a closer look
at my drinking patterns.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tail -n+2 food-diary | cut -d’,’ -f4 | sort | uniq -c | sort -rn
</span><span class='line'>  12 4
</span><span class='line'>   9 2
</span><span class='line'>   7 1
</span><span class='line'>   6 5
</span><span class='line'>   3 3
</span><span class='line'>   2 8
</span><span class='line'>   2 6
</span><span class='line'>   2 0
</span><span class='line'>   2</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>My most common daily drinking amounts were 1, 2, and 4 drinks per day. It was
very rare for me to go a day without drinking any alcohol. More alarmingly,
<a href="http://en.wikipedia.org/wiki/Binge_drinking#Definition">binge drinking</a> counts for <em>over 40% of my alcohol consumption!</em></p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tail -n+2 food-diary | while read line; do weekday=$(date -j -f “%Y-%m-%d” $(echo $line | cut -d’,’ -f1) “+%a”); alcohol=$(echo $line | cut -d’,’ -f4); echo $weekday $alcohol; done &gt; drinking.log
</span><span class='line'>$ for weekday in Mon Tue Wed Thu Fri Sat Sun; do count=$(grep $weekday drinking.log | cut -d’ ‘ -f2 | awk ‘{ sum+=$1} END {print sum}’); echo $count $weekday; done | sort -rn
</span><span class='line'>28 Wed
</span><span class='line'>27 Sat
</span><span class='line'>23 Mon
</span><span class='line'>20 Sun
</span><span class='line'>19 Fri
</span><span class='line'>15 Tue
</span><span class='line'>8 Thu</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>I drank most on Wednesdays and Saturdays; Mondays were also major drinking days,
which is surprising! By contrast, I drank much less than average on Thursdays.
When I narrow in on binge drinking, the pattern shifts slightly:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ grep -E “(5|6|7|8)$” drinking.log | cut -d’ ‘ -f1 | sort | uniq -c | sort -rn
</span><span class='line'>   4 Sat
</span><span class='line'>   3 Sun
</span><span class='line'>   2 Wed
</span><span class='line'>   1 Fri</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Wednesday is still an offender, but the weekends are clear culprits. <em>80% of my
binge drinking days fell on weekends.</em></p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tail -n+2 food-diary | cut -d’,’ -f1,4 | grep -E “(5|6|7|8)$” | while read line; do ds=$(echo $line | cut -d’,’ -f1); ts=$(date -j -f “%Y-%m-%d” $ds “+%s”); ts_next=$(echo “$ts + 86400” | bc); ds_next=$(date -j -f “%s” $ts_next “+%Y-%m-%d”); echo $line $(grep $ds_next food-diary | cut -d’,’ -f1,4); done
</span><span class='line'>2012-01-21,5 2012-01-22,5
</span><span class='line'>2012-01-22,5 2012-01-23,1
</span><span class='line'>2012-01-28,8 2012-01-29,2
</span><span class='line'>2012-02-01,6 2012-02-02,0
</span><span class='line'>2012-02-04,5 2012-02-05,3
</span><span class='line'>2012-02-10,6 2012-02-11,4
</span><span class='line'>2012-02-12,5 2012-02-13,3
</span><span class='line'>2012-03-14,8 2012-03-15,0
</span><span class='line'>2012-03-17,5 2012-03-18,5
</span><span class='line'>2012-03-18,5 2012-03-19,4</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Among days where I had 5 or more drinks, I had an average of 2.7 drinks the next day.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tail -n+2 food-diary | cut -d’,’ -f1,4 | grep -E “(0|1)$” | while read line; do ds=$(echo $line | cut -d’,’ -f1); ts=$(date -j -f “%Y-%m-%d” $ds “+%s”); tsprev=$(echo “$ts - 86400” | bc); dsprev=$(date -j -f “%s” $tsprev “+%Y-%m-%d”); echo $(grep $dsprev food-diary | cut -d’,’ -f1,4) $line; done
</span><span class='line'>2012-01-22,5 2012-01-23,1
</span><span class='line'>2012-01-23,1 2012-01-24,1
</span><span class='line'>2012-01-30,4 2012-01-31,1
</span><span class='line'>2012-02-01,6 2012-02-02,0
</span><span class='line'>2012-02-05,3 2012-02-06,1
</span><span class='line'>2012-02-06,1 2012-02-07,1
</span><span class='line'>2012-02-08,4 2012-02-09,1
</span><span class='line'>2012-03-14,8 2012-03-15,0
</span><span class='line'>2012-03-15,0 2012-03-16,1</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Among days where I had fewer than 2 drinks, I had consumed an average of 3.6 drinks the
previous day. This suggests a <em>see-saw pattern</em>: I would drink too much one day,
back off the next, and repeat.</p>

<h3 id="panic">Panic</h3>

<p>All of this skirts the real question:</p>

<p><blockquote><p>What caused me to have panic attacks?</p></blockquote></p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ for i in $(seq 2 4); do head -1 food-diary | cut -d’,’ -f$i; tail -n+2 panic-log | cut -d’,’ -f1 | while read ds; do ts=$(date -j -f “%Y-%m-%d” $ds “+%s”); tsprev=$(echo “$ts - 86400” | bc); dsprev=$(date -j -f “%s” $tsprev “+%Y-%m-%d”); echo $(grep $dsprev food-diary | cut -d’,’ -f1,2) $(grep $ds food-diary | cut -d’,’ -f1,$i) $ds; done; done
</span><span class='line'>caffeine
</span><span class='line'>2012-01-28,0 2012-01-29,0 2012-01-29
</span><span class='line'>2012-01-31,0 2012-02-01,0 2012-02-01
</span><span class='line'>2012-02-03,0 2012-02-04,0 2012-02-04
</span><span class='line'>2012-02-07,0 2012-02-08,1 2012-02-08
</span><span class='line'>2012-02-12,0 2012-02-13,0 2012-02-13
</span><span class='line'>2012-02-29
</span><span class='line'>2012-03-12,0 2012-03-13,1 2012-03-13
</span><span class='line'>sweets
</span><span class='line'>2012-01-28,0 2012-01-29,3 2012-01-29
</span><span class='line'>2012-01-31,0 2012-02-01,1 2012-02-01
</span><span class='line'>2012-02-03,0 2012-02-04,2 2012-02-04
</span><span class='line'>2012-02-07,0 2012-02-08,1 2012-02-08
</span><span class='line'>2012-02-12,0 2012-02-13,1 2012-02-13
</span><span class='line'>2012-02-29
</span><span class='line'>2012-03-12,0 2012-03-13,1 2012-03-13
</span><span class='line'>alcohol
</span><span class='line'>2012-01-28,0 2012-01-29,2 2012-01-29
</span><span class='line'>2012-01-31,0 2012-02-01,6 2012-02-01
</span><span class='line'>2012-02-03,0 2012-02-04,5 2012-02-04
</span><span class='line'>2012-02-07,0 2012-02-08,4 2012-02-08
</span><span class='line'>2012-02-12,0 2012-02-13,3 2012-02-13
</span><span class='line'>2012-02-29
</span><span class='line'>2012-03-12,0 2012-03-13,2 2012-03-13</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>I had no data for <code>2012-02-28</code>. Other than that, on days where I had reported
panic attacks, my <em>current- and previous-day consumption patterns</em> were:</p>

<ul>
  <li><strong>alcohol</strong>: 3.7 drinks that day, 3.8 the previous day (overall average is 3.1);</li>
  <li><strong>sweets</strong>: 1.5 sweets that day, 1.0 the previous day (overall average is 1.0);</li>
  <li><strong>caffeine</strong>: 0.3 caffeinated beverages that day, 0.0 the previous day (overall average is 0.1).</li>
</ul>

<p>This suggests that <em>reducing alcohol and sweets consumption does help</em>. The data
is less clear on caffeine; as previously mentioned, I had mostly cut out
caffeine by the time I started tracking.</p>

<h2 id="up-next">Up Next</h2>

<p>In the next post, I’ll run some of the statistical tests and transformations
mentioned previously on this same data. I’ll also compare this dataset with
another dataset gathered through
<a href="https://github.com/candu/qs-counters">qs-counters</a>, a simple lightweight tracking utility I built to
reduce friction in the recording process.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Panic!]]></title>
    <link href="http://candu.github.com/blog/2012/10/03/panic/"/>
    <updated>2012-10-03T17:47:00-07:00</updated>
    <id>http://candu.github.com/blog/2012/10/03/panic</id>
    <content type="html"><![CDATA[<p>In this post, I’ll tell the story of how I got started with self-tracking
and talk briefly about my first experiment.</p>

<!--more-->

<h2 id="my-journey-into-the-self-tracking-jungle">My Journey Into The Self-Tracking Jungle</h2>

<h3 id="first-a-video-for-context">First, A Video For Context</h3>

<p>If you’ve already seen my talk on panic attacks, feel free to skip to the next
section.</p>

<iframe src="http://player.vimeo.com/video/45860129" width="500" height="281" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
<p><a href="http://vimeo.com/45860129">Evan Savage - Panic</a> from <a href="http://vimeo.com/quantifiedself">Gary Wolf</a> on <a href="http://vimeo.com">Vimeo</a>.</p>

<h3 id="seeking-help">Seeking Help</h3>

<p>My success in confronting panic began with a <em>simple yet powerful insight</em>:</p>

<p><blockquote><p>I don’t know how to deal with this, but someone else might.</p></blockquote></p>

<p>Once I had this insight, <em>seeing a psychologist</em> was the natural next step.</p>

<ul>
  <li>As a <em>domain expert</em>, the psychologist knows where to find relevant
information for a wide variety of conditions. I can ask her for further
resources and receive <em>highly targeted recommendations</em>.</li>
  <li>As a <em>stranger</em>, the psychologist provides an <em>impartial and
non-judgmental sounding board</em>. I can discuss my thoughts, fears, and
experiences with her and feel safe doing so.</li>
</ul>

<p>As a side note, the former point reflects some of the promise of the
<em>Quantified Mass</em>. When you have a specific problem,
there is a subtle but crucial difference between</p>

<p><blockquote><p>What did others try?</p></blockquote></p>

<p>and</p>

<p><blockquote><p>What should I try next?</p></blockquote></p>

<p>While answering the first question is helpful, I’d argue that answering the
second is an order of magnitude more helpful.</p>

<h3 id="basic-research">Basic Research</h3>

<p>My psychologist recommended the
<a href="http://www.amazon.com/Anxiety-Phobia-Workbook-Edmund-Bourne/dp/1572248912">Anxiety and Phobia Workbook</a>.
As a survey of known symptoms, studies, treatments, and experiences, it gave me
a <em>much broader set of external inputs</em> to draw on. After reading the workbook
cover to cover, the natural next step was now to <em>combine these inputs into
something actionable</em>.</p>

<p>I identified specific treatments that seemed easy to implement. In retrospect,
my initial list was pretty large:</p>

<ul>
  <li><strong>Abdominal Breathing</strong>: by learning to <em>breathe from the abdomen</em>, you train
your body to avoid the sort of shallow chest breathing that can worsen an
attack.</li>
  <li><strong>Deep Relaxation</strong>: through <em>meditation, progressive muscle relaxation, or
other prolonged exercises</em>, you remove sources of physical tension in the body.</li>
  <li><strong>Daily Exercise</strong>: with <em>30 minutes of exercise per day</em>, you reduce overall
stress and increase fitness.</li>
  <li><strong>Positive Self-Talk</strong>: by <em>replacing internal
monologues</em> like “oh no, I’m having a heart attack” with more positive ones
like “I’ve dealt with this before, I’m in control”, you stop this
mental feedback loop from making your attack worse.</li>
  <li><strong>Desensitization</strong>: by <em>gradually exposing yourself to panic triggers in a
safe environment</em>, you sever the mental links that tie those triggers to
panic.</li>
  <li><strong>Assertiveness</strong>: by <em>expressing yourself in a constructive and
assertive manner</em>, you gain a sense of control over your environment
that is also useful in thwarting an attack.</li>
  <li><strong>Diet Modification</strong>: by <em>eliminating or reducing consumption of caffeine,
simple sugars, and alcohol</em>, you reduce baseline stress.</li>
  <li><strong>Supplements</strong>: by <em>taking B-complex and C vitamins</em>, your body gets the
raw materials necessary to regulate stress.</li>
</ul>

<p>All of these take <em>at most 30 minutes per day</em>, and many are <em>passive habits</em>
that rely on <em>small behavior modifications</em>.
<a href="https://www.facebook.com/events/268817716510713/">Small changes in habit</a>
are often more effective than large changes, as they are <em>easier to maintain</em>.</p>

<h2 id="my-first-experiment">My First Experiment</h2>

<p>Building this list led me to another question:</p>

<p><blockquote><p>How will I know if my condition is improving?</p></blockquote></p>

<p>This is where <em>self-tracking</em> comes in. To answer this question, I needed
to know what I was doing and whether it was working. I decided that I would
keep a <em>recovery journal</em>, which I divided into four sections.</p>

<ol>
  <li><strong>Weekly Practice Record</strong>: this was an overview of my activity. Every day,
I would check off each treatment I successfully followed. I also had areas
for weekly goals and notes.</li>
  <li><strong>Daily Record of Exercise</strong>: every day, I would fill in either the duration
and type of exercise or a reason for not exercising.</li>
  <li><strong>Food Diary</strong>: every day, I would fill in my caffeine, sugar, and alcohol
consumption. I would also fill whether I took B-complex and C vitamins.</li>
  <li><strong>Panic Triggers and Responses</strong>: if I experienced a panic attack, I would
note the date and time, the severity, what triggered it, what specific
symptoms I experienced, and how I dealt with it.</li>
</ol>

<p>You can view and print the log sheets
<a href="https://docs.google.com/folder/d/0B4lRh7NaNiTMNDE2ODE3ZTMtNWVjZC00M2VlLTg1NWUtZjdmZTlkMGI2NTZm/edit">on Google Docs</a>.</p>

<p>Keeping these logs took no more than five minutes per day. Tracking mechanisms
are most effective when they have <em>low overhead</em>, as this lowers the willpower
barrier to using them regularly.</p>

<h3 id="a-diversion-on-self-tracking-design">A Diversion On Self-Tracking Design</h3>

<p><blockquote><p>How can we design systems when we don’t know what we’re doing?</p><footer><strong>Bret Victor</strong> <cite><a href='http://worrydream.com/LadderOfAbstraction/'>Up and Down the Ladder of Abstraction</a></cite></footer></blockquote></p>

<p>Although I cribbed the individual sections almost verbatim from the workbook,
their specific combination has some curious results.</p>

<p>The <em>broad</em> view of Section 1 is complemented by the <em>deep</em> view of Sections
2-3. In the data visualization world, having
<a href="http://worrydream.com/LadderOfAbstraction/">multiple levels of abstraction</a>
helps the viewer grasp the whole picture without losing their hold on specifics.
By looking at the broad view, I knew my overall progress; by looking at the
deep views, I could see the areas I needed to focus on.</p>

<p>Section 4 provides the <em>feedback loop</em>. Without this section,
I can’t answer my earlier question:</p>

<p><blockquote><p>How will I know if my condition is improving?</p></blockquote></p>

<p>My self-tracking was very <em>goal-directed</em>: I had a specific problem that I
wanted to solve. There is another kind of self-tracking, one that I
think many people ignore, and that is <em>exploratory</em> self-tracking.</p>

<p>Imagine this same journal without Section 4. None of the treatments are
specific to panic, so they could reasonably be followed by anyone. Without the
goal of confronting panic, there is <em>greater room for curiosity</em>. You could add
more experiments, play with correlations, ask weirder questions like
“what happens if I eat a lot of <a href="http://quantifiedself.com/butter/">butter</a>?”
<em>Without imposing goals, there is no failure or success</em>, and that can be both
a curse and a blessing. The curse is that you might not measurably improve
yourself. The blessing is that you might not care!</p>

<p>I believe that, much like a
<a href="http://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>
system, the Quantified Self community <em>needs both modes of self-tracking to
thrive</em>.</p>
]]></content>
  </entry>
  
</feed>
